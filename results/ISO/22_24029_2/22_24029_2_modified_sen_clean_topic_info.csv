Topic,Count,Name,Representation,Representative_Docs
-1,92,-1_robustness_neural_type_properties,"['robustness', 'neural', 'type', 'properties', 'output', 'tabular', 'model', 'inputs', 'example', 'domains']","['formal methods can be applicable on time series as long as it is possible to analyze the type of data stored at each instance', '6.2 types of formal methods applicable 6.2.1 general 6.2.1.1 consideration on the types of formal methods applicable subclause 6.2 describes existing formal methods applicable to the assessment of the robustness of neural networks', 'however formal methods can \ufeff\x08 bring new information on the neural network robustness within specific domain']"
0,41,0_neural_networks_classification_speech,"['neural', 'networks', 'classification', 'speech', 'linear', 'applications', 'example', 'plnns', 'text', 'types']","['for example suppose when given concrete image for which the neural network outputs the label car the following question can be asked does the network output different label if the value of an arbitrary pixel in the image is modified this question can be formulated as formal mathematical statement that is either true or false for given neural network and image', 'applications of neural networks deal with data types such as image times series natural language graph or tabular', '6.1.2.4 natural language data natural language data types based on text and speech can be processed by neural networks']"
1,30,1_robustness_neural_testing_networks,"['robustness', 'neural', 'testing', 'networks', 'stage', 'design', 'development', 'structural', 'criteria', 'assessment']","['at each stage of the life cycle the document presents criteria that are applicable to assess the robustness of neural networks and to establish how neural networks are verified by formal methods', '3.13 binarized neural network neural network having parameters that are primarily binary 3.14 recurrent neural network neural network maintaining an internal state which encodes what the neural network has learned after processing subsequence of the input data 3.15 transformer neural network transformer neural network using self-attention mechanism to weight the effect of different parts of the input data during processing 3.16 model checking formal expression of theory 3.17 structural-based testing glass-box testing white-box testing structural testing dynamic testing in which the tests are derived from an examination of the structure of the test item note to entry structure-based testing is not restricted to use at component level and can be used at all levels e.g', 'source iso/iec/ieee 29119-1:2022 3.80 3.18 closed-box testing specification-based testing black-box testing testing in which the principal test basis is the external inputs and outputs of the test item commonly based on specification rather than its implementation in source code or executable software source iso/iec/ieee 29119-1:2022 3,75 abbreviated terms ai artificial intelligence bnn binarized neural networks gnn graph neural networks milp mixed-integer linear programming mri magnetic resonance imaging plnn piecewise linear neural networks relu rectified linear unit rnn recurrent neural networks sar synthetic aperture radar smc satisfiability modulo convex smt satisfiability modulo theories robustness assessment 5.1 general in the context of neural networks robustness specifications typically represent different conditions that can naturally or adversarially change in the domain see 5.2 in which the neural network is deployed']"
2,29,2_images_expressed_intensity_organ,"['images', 'expressed', 'intensity', 'organ', 'pixels', 'variation', 'blur', 'dimension', 'features', 'formal']","['while feature- based perturbations are continuous and can be handled formally in similar manner to pixel intensity variations in images structural perturbations are discrete and therefore require the development of specialized formal techniques', 'for example the lighting of the image can be expressed as variation of intensity of the pixels', 'the size of the images is by images are taken at the same distance the angle of the organ is always centred on the image and the images all come from the same machine']"
3,26,3_formal_networks_methods_neural,"['formal', 'networks', 'methods', 'neural', 'architectures', 'types', 'binary', 'bnn', 'footprint', 'model']","['6.1.1.3 binarized neural networks in binarized neural networks bnn all activations are binary making these networks memory efficient and computationally efficient enabling the use of specialized algorithms for fast binary matrix multiplication', '\ufeff\x08 applicability of formal methods on neural networks 6.1 types of neural network concerned 6.1.1 architectures of neural networks 6.1.1.1 general neural networks can be designed and built using different kinds of architectures', 'subclause 6.1.1 describes formal techniques that have been developed for the following architectures piecewise linear neural networks binarized neural networks recurrent neural networks and transformer networks']"
4,20,4_reachability_agent_overapproximation_reach,"['reachability', 'agent', 'overapproximation', 'reach', 'network', 'stochastic', 'activation', 'collision', 'probabilistic', 'reachable']","['reachability property checks whether an ai agent can reach set of states when using the neural network to control itself in given environment', '5.6.2 reachability criterion reachability criterion expresses reachability property over given set of initial states', 'for deterministic environment the reachability property expresses whether or not it is possible for the ai agent to reach particular set of states']"
5,18,5_relevance_evaluation_criterion_expert,"['relevance', 'evaluation', 'criterion', 'expert', 'diagnostic', 'traceability', 'correspondence', 'level', 'lead', 'manual']","['5.5.2 relevance criterion relevance criterion expresses relevance property over domain which requires demonstration of link between each input and the outputs', 'in case of an automatic confirmation the evaluation should rely on clear relevance target on the data', 'confirming the result of relevance criterion can either be done manually through direct confirmation or be done automatically through an evaluation of the correspondence against relevance target']"
6,16,6_rounding_floating_754_operators,"['rounding', 'floating', '754', 'operators', 'rearranging', '2019', 'ieee', 'errors', 'numerical', 'accuracy']","['quantization using smaller floating-point operations or fixed-point arithmetic change in the rounding process change in the implementation of low-level numerical operators e.g', 'for example \ufeff\x08 standard floating-point arithmetic operations such as addition or division have rounding error that can be bounded by the value of the unit in the last place of the result', 'when ieee 754:2019 correctly rounded operators are not used then verifier can approximate the rounding done on each operator']"
7,16,7_sensitivity_criterion_variation_threshold,"['sensitivity', 'criterion', 'variation', 'threshold', 'inputs', 'parameters', 'extent', 'neural', 'sensitive', 'thresholds']","['for comparison to be accurate the following requirements shall be met the neural networks shall perform the same task the sensitivity criterion shall be used on the same domain the sensitivity criterion shall prove the same objective', 'when sensitivity analysis is used to determine whether neural network stays bounded the sensitivity analysis shall be used over domain', '5.4 sensitivity 5.4.1 sensitivity property sensitivity property on neural network expresses the extent to which the output of neural network varies when its inputs are changed']"
8,15,8_verification_satisfiability_smt_deterministic,"['verification', 'satisfiability', 'smt', 'deterministic', 'methods', 'solvers', 'checking', 'model', 'programming', 'glass']","['verification is then achieved by using methods like boolean satisfiability and integer linear programming', 'other verification methods view the plnn as global optimization problem and use method like satisfiability modulo theories smt solver', '6.2.2 solver mixed-integer linear programming milp solvers and satisfiability modulo theories smt solvers are deterministic glass-box and typically complete verification methods']"
9,15,9_domain_unbounded_attributes_defined,"['domain', 'unbounded', 'attributes', 'defined', 'length', 'objects', 'limitation', 'finite', 'rgb', 'bit']","['note to entry an attribute is used to describe bounded object even though the domain can be unbounded', '3.3 bounded domain set containing finite number of objects example the domain of all valid 8-bit rgb images with n-pixels is bounded by its size which is at most n. example the number of all valid english sentences is infinite therefore this domain is unbounded', '3.4 bounded object object represented by finite number of attributes note to entry contrary to bounded object an unbounded object is represented with an infinite number of attributes']"
10,14,10_attributes_semantic_defining_domains,"['attributes', 'semantic', 'defining', 'domains', 'features', 'instance', 'tasks', 'agent', 'processing', 'relations']","['however other domains can be expressed through non-numerical attributes including natural language processing graph and big code the use of automatically learning from existing code', 'for domains where input features have semantic meaning for example air traffic collision avoidance systems the global properties can be specified by defining valid input values for the input features expected in real-world deployment', 'in some cases the attributes are numerical such that it can be easy to model some meaningful variation of the attributes']"
11,13,11_robustness_operates_assess_perturbations,"['robustness', 'operates', 'assess', 'perturbations', 'safe', 'heating', 'faulty', 'mode', 'alerting', 'degradation']","['an additional criterion should be expressed on the difference observed in order to verify if the eventual degradation of the robustness is acceptable or not', 'alerting the operator or switching to fail-safe mode can be taken if and when the level of robustness required is not achieved', '7.5.2 robustness on domain of operation when system is put in operation it can be difficult to guarantee that it operates in the intended domain of use on which it has been specified and validated initially']"
12,13,12_output_decoder_representations_generate,"['output', 'decoder', 'representations', 'generate', 'inputs', 'recording', 'factors', 'partition', 'aggregate', 'parallel']","['this step is then repeated multiple times in parallel for all parts of the input successively generating new internal representations', 'while doing this it uses self-attention to aggregate information from all of the other parts of the input to generate new internal representation for the input', 'while doing this the decoder attends to the other previously generated parts of the output and also factors in the internal representations generated by the encoder']"
13,13,13_verifiers_box_testing_verifier,"['verifiers', 'box', 'testing', 'verifier', 'modifications', 'model', 'accuracy', 'require', 'coverage', 'encrypted']","['it is encrypted verifiers using glass-box testing are not applicable', 'this can make verifiers using closed-box testing less precise than verifiers using glass-box testing', '6.2.1.4 verifiers using glass-box testing model aware vs verifiers using closed-box testing model unaware verifiers using glass-box testing require access to the model i.e']"
14,12,14_local_properties_robustness_dataset,"['local', 'properties', 'robustness', 'dataset', 'deterministic', 'car', 'classified', 'samples', 'verifying', 'counterexample']","['it is more common to verify local robustness properties than global robustness properties as the former are easier to specify', 'drawback of verifying local robustness properties is that the guarantees are local to the provided test sample and do not extend to other samples in the dataset', 'robustness properties can be local or global']"
15,12,15_stages_robustness_terminology_roles,"['stages', 'robustness', 'terminology', 'roles', 'quality', 'characteristics', 'developer', 'learning', 'platform', 'standards']","['iso/iec 22989:2022 information technology artificial intelligence artificial intelligence concepts and terminology iso/iec 23053:2022 framework for artificial intelligence ai systems using machine learning ml terms and definitions for the purposes of this document the terms and definitions given in iso/iec 22989:2022 iso/iec 23053:2022 and the following apply', '\ufeff\x08 robustness during the life cycle 7.1 general the life cycle of an ai system drawn from iso/iec 22989:2022 is described in figure and is composed of stages', 'figure example of ai system life cycle model stages and high-level processes iso/iec 22989:2022 5.19 defines set of ai stakeholder roles and sub-roles including ai provider ai producer ai developer ai customer etc']"
16,10,16_relevance_criterion_ordering_developer,"['relevance', 'criterion', 'ordering', 'developer', 'matches', 'neural', 'outputs', 'logic', 'predictive', 'objective']","['for neural network performing predictive analysis of time series relevance criterion can be used to check if the predicted event matches consequential logic acceptable for the ai developer e.g', 'for comparison to be accurate the following requirements shall be met the neural networks shall perform the same task the relevance criterion shall be used on the same domain the relevance criterion shall prove the same objective', '5.5 relevance 5.5.1 relevance property relevance property on neural network expresses an ordering of the impact of the inputs on the outputs']"
17,10,17_stability_inputs_criterion_classified,"['stability', 'inputs', 'criterion', 'classified', 'decision', 'regression', 'neural', 'noisy', 'domain', 'chaotic']","['3.5 stability extent to which the output of neural network remains the same when its inputs are changed note to entry more stable neural network is less likely to change its output when input changes are noise', 'for neural network doing regression stability criterion assesses whether or not the regression remains stable on the domain', '5.3 stability 5.3.1 stability property stability property expresses the extent to which neural network output remains the same when its inputs vary over specific domain']"
18,10,18_developer_features_overapproximations_hypothesis,"['developer', 'features', 'overapproximations', 'hypothesis', 'integration', 'simulation', 'rearrange', 'production', 'impacts', 'interpret']","['the ai developer should document clearly the hypothesis used to make such overapproximations', '7.2.2 identifying the recognized features identifying the features recognized by the neural network allows the ai developer to better understand and explain or interpret the behaviour of the neural network', 'the ai developer should document clearly the hypothesis used to make such overapproximations']"
19,9,19_methods_formal_trials_computational,"['methods', 'formal', 'trials', 'computational', 'replace', 'hardware', 'statistical', 'practice', 'verification', 'software']","['using formal methods at this stage does not replace other means of verification and validation such as statistical testing or field trials', 'formal methods are mathematical techniques for rigorous specification and verification of software and hardware systems with the goal to prove their correctness', 'formal methods relying on symbolic calculus logical calculus or computational methods can be used to achieve such goal']"
20,9,20_references_clause_persons_constitutes,"['references', 'clause', 'persons', 'constitutes', 'cited', 'amendments', 'parent', 'documents', 'requirement', 'scalability']","['normative references the following documents are referred to in the text in such way that some or all of their content constitutes requirements of this document', 'for dated references only the edition cited applies', 'for undated references the latest edition of the referenced document including any amendments applies']"
21,9,21_stability_regularity_hold_behaviour,"['stability', 'regularity', 'hold', 'behaviour', 'criterion', 'domains', 'properties', 'chaotic', 'datasets', 'stable']","['stability criterion shall define at least the domain value space and output value space on which it has been measured and the stability property expected', 'stability property should be used on domains of uses which in terms of expected behaviour present some regularity properties', '5.3.2 stability criterion stability criterion establishes whether stability property holds within specific domain not just for specific set of examples or for subset of the domain such as training or validation datasets']"
22,9,22_layer_transformer_encoder_cells,"['layer', 'transformer', 'encoder', 'cells', 'neurons', 'space', 'networks', 'zonotopes', 'embeddings', 'shapes']","['this region can be represented exactly or approximately using certain geometric shapes such as boxes zonotopes and polyhedra or as custom abstract domains for neural networks this region is then propagated through the neural network such that every layer is sequentially applied to the input region', 'for each of these positions the bounds are computed from the first sub-layer to the last sub-layer', 'transformer layer is decomposed into number of sub-layers such that in each sub-layer some operations are performed on the neurons in that sub-layer']"
23,9,23_perturbations_region_network_describable,"['perturbations', 'region', 'network', 'describable', 'approximations', 'relaxations', 'semidefinite', 'equivalence', 'outputs', 'measuring']","['applying perturbation into an input of the neural network is seen as applying function to the inputs in order to modify them', 'depending on the layer this can introduce approximations outputs that are unreachable from the input region finally an output region captures all possible outputs of the network for input perturbations that are formed according to the robustness specifications', '7.3.3 measuring perturbation impact by relying on the description of the domain planned for the use of neural network it is possible to identify types of perturbation that the neural network input can be subjected to']"
24,9,24_classes_overlap_separated_separability,"['classes', 'overlap', 'separated', 'separability', 'classifier', 'overlaps', 'spread', 'outputs', 'starts', 'sensitivity']","['the spread of values of the attributes should be increased gradually in order to measure what classes are starting to overlap with each other', 'the process stops when all classes outputs overlap with all other class outputs', 'separability analysis results are based on the order in which classes start to overlap and the size of the domain on which these overlaps start to occur']"
