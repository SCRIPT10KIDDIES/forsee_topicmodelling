Topic,Count,Name,Representation,Representative_Docs
-1,55,-1_bias_cognitive_information_development,"['bias', 'cognitive', 'information', 'development', 'risk', 'organization', 'annotations', 'population', 'dataset', 'deployment']","['information made available by ai technology providers in the course of procurement should include intended context of use and related assumptions known system limitations recommended patterns of interaction between humans and the ai system during use relevant trade-offs in algorithms machine learning algorithms and ml models development that can affect or relate to unwanted bias example how the model is used at inference time where taking the argmax argument of the maximum for classification problems or using deterministic ranking risks amplifying small biases in model scores data collection modification and curation processes that can relate to bias such as imputation or augmentation testing strategies used during the design and development or the verification and validation stage of the ai system including acceptance criteria and the use of proxies in ml modelling', '5.2.3 data annotations where risks have been identified in relation to unwanted bias the organization shall consider biases that result from the disproportionate with respect to the real-world distribution availability of annotations of data types of human cognitive biases including in relation to the annotation of data types of processes and decisions made during the life cycle that can be impacted by types of human cognitive bias', 'where risks have been identified in relation to unwanted bias the organization shall consider types of data biases that can be present and the effects of feature selection types of human cognitive biases that can be present in the individuals involved in selecting features missing or unexpected feature values and unwanted imbalance types of processes and decisions made during the life cycle that can be impacted by types of human cognitive bias interactions between system components biases that can result from the disproportionate with respect to the real-world distribution availability of datasets or features biases that can be embedded in processes involved in selecting features presence of proxies for demographic categories distribution of group membership in training validation or test data and its representativeness of the population to which the system will operate distribution of positive or negative outcomes across demographic groups other forms of statistical or computational bias that can be relevant']"
0,30,0_bias_federated_nodes_distributed,"['bias', 'federated', 'nodes', 'distributed', 'retraining', 'regularization', 'regression', 'techniques', 'edge', 'classification']","['the following additional risk treatments should be considered in the approach monitoring of unwanted bias during operation monitoring of changes in the training data profile where model retraining occurs technical mechanisms to alert operators if processing is outside of defined usage limits technical mechanisms to identify if production data contains inputs that are outside those assessed in verification activities mechanisms for end users to identify potential unwanted bias and bring it to the attention of operators meaningful human oversight redress for adverse outcomes', 'to account for such scenarios organizations can use techniques including the following changing temperature or similar settings that control randomness in system outputs content moderation via rules or simpler ai systems that identify problematic output and restrict their output to users fine-tuning retraining or transfer learning based on ground truth training data or data from within an organization providing pre-approved responses for common or foreseeably problematic inputs strong meta-prompts that acknowledge diverse user populations and instruct models to avoid stereotyping disparaging or otherwise toxic outputs including user feedback and redress mechanisms', 'training methodologies such as federated learning require one orchestrating entity to combine the individual training at each distributed training node by using specific aggregation algorithm']"
1,24,1_bias_gender_metadata_classifiers,"['bias', 'gender', 'metadata', 'classifiers', 'risks', 'norms', 'accessibility', 'effect', 'mitigation', 'information']","['but gender information can be collected and included as metadata in order to enable testing for unwanted bias based on gender', '5.4 re-evaluation continuous validation operations and monitoring 5.4.1 general an organization shall document and adhere to its approach to ensuring that the risk treatments identified to address unwanted bias see 5.1.5 continue to have the desired effect on an ongoing basis', 'additional elements monitored for external change are accessibility concerns including accessibility to opt-outs and redress mechanisms and accommodations for people with disabilities monitoring effectiveness of bias mitigation controls applied bias mitigation approaches can fail or worsen bias risks ongoing user feedback']"
2,24,2_testing_representativeness_correctness_target,"['testing', 'representativeness', 'correctness', 'target', 'entry', 'dataset', 'training', 'imputations', 'augmentations', 'models']","['note to entry representative test data enables verification that an ai system achieves an acceptable level of functional correctness 3.2.7 for the target population 3.3.10', 'there are three types of testing that are relevant to detecting bias static testing of the training data to identify risks related to unwanted bias dynamic testing of the ml model including data pre-processing to evaluate functional correctness dynamic testing of the ai system to evaluate functional correctness for at-risk groups', 'note to entry representative training data can enable training machine learning model that achieves an acceptable level of functional correctness 3.2.7 for the target population 3.3.10']"
3,20,3_disposal_processes_organization_management,"['disposal', 'processes', 'organization', 'management', 'roles', 'objectives', 'documentation', 'responsibilities', 'ieee', 'entity']","['source iso/iec 42001:2023 3.4 3.1.10 organization person or group of people that has its own functions with responsibilities authorities and relationships to achieve its objectives note to entry the concept of organization includes but is not limited to sole-trader sole proprietor company corporation firm enterprise authority partnership charity or institution or part or combination thereof whether incorporated or not public or private', 'an ethics policy organizational processes and decisions as part of ai governance surveys of past known failure modes based on resources such as the organization documentation on its prior system failures or in ai incident databases assumptions processes decisions and related activities made by individuals or groups across the ai life cycle', 'annex informative life cycle processes map iso/iec/ieee describes system life cycle processes and iso/iec/ieee 12207:2017 describes software life cycle processes']"
4,18,4_testing_29119_ieee_activities,"['testing', '29119', 'ieee', 'activities', 'dynamic', 'validation', 'criteria', 'performed', 'assess', 'entry']","['3.4.7 test plan detailed description of test objectives 3.4.6 to be achieved and the means and schedule for achieving them organized to coordinate testing 3.4.8 activities for some test item 3.4.5 or set of test items source iso/iec/ieee 29119-2:2021 3.50 modified the notes to entry have been removed', '3.4.4 test completion report test summary report report that provides summary of the testing 3.4.8 that was performed source iso/iec/ieee 29119-3:2021 3.9 3.4.5 test item test object work product to be tested source iso/iec/ieee 29119-1:2022 3.107 modified the example has been removed', '3.4.3 static testing testing 3.4.8 in which test item 3.4.5 is examined against set of quality or other criteria without the test item being executed source iso/iec/ieee 29119-1:2022 3.20 modified the example has been removed']"
5,16,5_risks_management_expectations_incorporation,"['risks', 'management', 'expectations', 'incorporation', 'documentation', 'policies', 'audits', 'audited', 'organizations', 'external']","['organizations should monitor and document external change affecting risks of unwanted bias in compliance with the organization risk management process', 'other aspects of incorporation with broader risk management can include documentation of change management plans incorporation of documentation into organizational inventories communication with senior management relating to bias risks', 'organizations should ensure that agreements with third parties include appropriate measures to treat the risk of unwanted bias considering the role of the organization and third parties in particular where an organization is unable to obtain full transparency on technical aspects of the system']"
6,14,6_bias_worker_workplace_leave,"['bias', 'worker', 'workplace', 'leave', 'employees', 'stakeholders', 'assess', 'subjects', 'feedback', 'design']","['iso when applied to an ai system covers preventing unwanted bias by means of inclusive design regularly assessing ai systems for unwanted bias effect on consumers especially in vulnerable situations those systems that are biased in ways that are unwanted those systems that create unwanted discrimination those systems that cause harm', 'this can include users who operate or interface with an ai system as they can offer personal feedback on unwanted bias that has affected them as individuals example front-line workers whose familiarity with digital technology is at lower level than that of an ai application main beneficiaries or target audience', 'examples of ai use in the workplace are recruitment algorithms to design job advertisements screen job applications test candidates competencies check their records and conduct or assess interviews workplace decision algorithms to organize work shifts assign everyday tasks to workers allocate workers to different teams or projects or provide routine self-service human resources activity salaries and benefits annual leave sick leave work expense claims performance management algorithms that can track physical or digital worker activity check employees emails and other messages looking for keywords or conducting sentiment analysis assess workers against output or targets use customer ratings to measure employee performance and finally take all of the above and convert it into recommendations about which employees to promote award bonuses or terminate']"
7,14,7_process_distributed_validation_design,"['process', 'distributed', 'validation', 'design', 'training', 'cloud', 'apply', 'edge', 'managing', 'feature']","['while the ai system life cycle stage applicable to these techniques is discussed applicable techniques should be selected during the life cycle inception stage whenever possible', 'table a.1 ai system life cycle mapping life cycle process related subclauses in this document 6.1.1 acquisition process 5.1.3 6.1.2 supply process 5.1.3 6.3.1 project planning process 5.1.1 6.3.2 project assessment and control process 6.3.3 decision management process multiple 6.3.4 risk management process 5.1 5.2 5.3 6.3.5 configuration management process 6.3.6 information management process 6.3.7 measurement process 5.3 6.3.8 quality assurance process 5.3 6.4.1 business or mission analysis process 5.1 6.4.2 stakeholder needs and requirements definition process 5.1.1 6.4.3 system requirements definition process 5.1 5.2 6.4.4 architecture definition process 5.2 6.4.5 design definition process 5.2 6.4.6 system analysis process 6.4.7 knowledge acquisition process 5.1.4 5.2 6.4.8 ai data engineering process 5.1.4 5.2 6.4.9 implementation process 5.2 6.4.10 integration process 6.4.11 verification process 5.1.6 5.3 6.4.12 transition process 6.4.13 validation process 5.3 6.4.14 continuous validation process 5.4 6.4.15 operation process 5.4 6.4.16 maintenance process 5.4 6.4.17 disposal process 5.5 annex informative potential impacts of unwanted bias on different types of specific user b.1 workers needs employers are increasingly investing in ai-based digital monitoring analysis and decision-making solutions to inform advise supplement and in some cases completely replace decision-making by employees', 'the ai system life cycle as shown in iso/iec 22989:2022 figure can be applied to such distributed training deployment at each of the training edge nodes on the distributed network and to the orchestrating entity managing the overall training possibly on the cloud']"
8,13,8_acceptance_criteria_metrics_practices,"['acceptance', 'criteria', 'metrics', 'practices', 'normative', 'provisions', 'tolerances', 'gaming', 'testable', 'text']","['5.1.6 acceptance criteria an organization shall determine appropriate tolerances for functional correctness', 'the organization shall determine if these differences are acceptable against the acceptance criteria', 'acceptance criteria shall be documented in the context of the intended use and operating conditions']"
9,12,9_quality_disposition_5259_data,"['quality', 'disposition', '5259', 'data', 'source', 'records', 'characteristic', 'definitions', 'software', 'provenance']","['further information on data quality measures can be found in iso/iec 5259-2', '3.1.4 data subject person to whom data refer source iso 25237:2017 3.18 3.1.5 data quality model defined set of characteristics which provides framework for specifying data quality requirements and evaluating data quality source iso/iec 25012:2008 4.6 3.1.6 disposition range of records processes associated with implementing records retention destruction or transfer decisions which are documented in disposition authorities 3.1.7 or other instruments source iso 30300:2020 3.4.8 3.1.7 disposition authority instrument that defines the disposition 3.1.6 actions that are authorized or required for specified records source iso 30300:2020 3.5.4 3.1.8 intended operating conditions conditions under which an ai system is meant to function note to entry conditions can include resource usage environmental factors geographic location of use time of use training provided to operators and the target population', ""3.2 artificial intelligence 3.2.1 data quality characteristic of data that the data meet the organization 's 3.1.10 data requirements for specified context source iso/iec 5259-1:2024 3.4 3.2.2 data quality characteristic category of data quality attributes that bears on data quality 3.2.1 source iso/iec 5259-1:2024 3.5 3.2.3 data quality measure variable to which value is assigned as the result of measurement of data quality characteristic 3.2.2 source iso/iec 5259-1:2024 3.7 3.2.4 data provenance provenance information on the place and time of origin derivation or generation of data set proof of authenticity of the data set or record of past and present ownership of the data set source iso/iec 5259-1:2024 3.16 3.2.5 extreme data type of sample that is an outlier with respect to the real-world distribution 3.2.6 feature machine learning measurable property of an object or event with respect to set of characteristics note to entry features play role in training and prediction""]"
10,12,10_data_dataset_values_labels,"['data', 'dataset', 'values', 'labels', 'providers', 'groups', 'iid', 'provenance', 'identifiable', 'disclosure']","['5.1.4 data sources organizations shall document and evaluate unwanted bias in relation to sources of data used by the ai system data selection criteria and processes data collection procedures including the mechanisms for requesting informed consent and for revoking consent for future users provenance of the data collection input preprocessing labelling and label cleaning mechanism impacts of dataset collection on data subjects', 'where appropriate for the use case the following aspects of each data source shall be evaluated and documented intended use and purpose of the dataset created including specific tasks identification of dataset creators and sources of funding if applicable composition of the dataset including nature size labels relations errors redundancies noise and missing information of the instances in the dataset completeness regarding the contents of the data such as confidential information sensitive data that reveals identifiers of individuals subpopulations and groups and information on missing features for each group of relevant stakeholders terms of use and license accuracy including the amount of inaccurate data contained within the dataset and the inaccuracy for each group of stakeholders currency including potential effects of the time of collection on accuracy appropriateness in terms of amount of toxic or offensive data contained in the dataset consistency including labels e.g', 'the measures selected by the organization shall enable the assessment of whether the data contains an inappropriate imbalance among feature values among labels or among other categories whether the data is representative and relevant with respect to the expected production data whether the data is sufficiently diverse both within and among groups whether the proportion of instances with missing or corrupted content is evenly distributed for each at- risk group whether the data format and the amount of information contained is consistent for each group']"
11,10,11_edition_references_authoritative_provider,"['edition', 'references', 'authoritative', 'provider', 'records', 'ieee', 'electropedia', 'market', 'utilization', 'useability']","['for undated references the latest edition of the referenced document including any amendments applies', 'iso and iec maintain terminology databases for use in standardization at the following addresses iso online browsing platform available at iec electropedia available at 3.1 general 3.1.1 authoritative record record which possess the characteristics of authenticity reliability integrity and useability source iso 30300:2020 3.2.3 3.1.2 consumer vulnerability state in which an individual can be placed at risk of harm during their interaction with or decision by service provider due to the presence of personal situational and market environment factors source iso 22458:2022 3.5 modified added reference to decision by service provider', 'source iso/iec 42001:2023 3.1 3.1.11 records process set of activities for managing authoritative records source iso 30300:2020 3.4.13 3.1.12 user individual or group that interacts with system or benefits from system during its utilization source iso/iec/ieee 15288:2023 3.53 modified note to entry has been removed']"
12,8,12_external_changes_deployment_markets,"['external', 'changes', 'deployment', 'markets', 'capabilities', 'reassessment', 'scenarios', 'customize', 'attention', 'mitigation']","['external changes in the use of ai systems can affect bias after ai systems are evaluated and deployed', '5.4.2 external change depending on their significance external changes can necessitate full reassessment of the ai system for unwanted bias', 'the following are examples of how some external changes can affect decision-making processes deployment of an existing ai system to different environment including different users target markets or data sources can change the risks and require the ai system to be reassessed for unwanted bias']"
13,8,13_methods_guidance_implementation_machine,"['methods', 'guidance', 'implementation', 'machine', 'validate', 'automate', 'tools', 'algorithmic', 'learning', 'practices']","['this document does not address applicability of the described methods outside of the defined ml tasks', '6.2 algorithmic and training techniques 6.2.1 general an ai system can be composed of one or more ml models either used independently or in combination', 'implementation guidance ml tools can be procured developed in-house or combination of the two']"
14,8,14_partners_requirements_organization_audit,"['partners', 'requirements', 'organization', 'audit', 'stakeholders', 'disclosure', 'legal', 'makers', 'developing', 'auditing']","['the exact extent of non-disclosure by ai producers and partners and the existence of legal requirements affecting disclosure shall be disclosed and justified', 'organizations responsible for the deployment or operation of an ai system shall consider ai subjects about whom automated decisions are made or who share an operating environment with an ai system example recommender system receiving input from user ensures that variations in ability are accounted for in applications that are used by native and non-native language speakers', 'decision-makers within an organization designing developing deploying or using an ai system ai partners including ai auditors who are required to perform conformity assessment on an ai system example auditing teams consider the diversity of the audited organization and the audited organization target audience customers and other interested parties when conducting the audit to prevent unwanted biases affecting the audit']"
15,8,15_biases_matches_provider_communities,"['biases', 'matches', 'provider', 'communities', 'players', 'tournaments', 'research', 'chess', 'visibility', 'surveys']","['example this information can be used to uncover biases associated with mechanisms that only the data provider has visibility on as they are part of their internal process', 'studies surveys or focus groups with potentially affected individuals and communities product management and user-interaction/user-experience research activities to prioritize and incorporate user and customer feedback', 'this can enable acceptance of the presence of an observed but mitigated bias that is deemed appropriate for given use case or uncover biases associated with mechanisms used by the data provider']"
