Topic,Count,Name,Representation,Representative_Docs
-1,141,-1_machine_models_classification_regression,"['machine', 'models', 'classification', 'regression', 'spam', 'tasks', 'inputs', 'negatives', 'neural', 'trained']","['figure ml methods categorized as supervised machine learning unsupervised machine learning and reinforcement machine learning 7.2 supervised machine learning in supervised machine learning ml models are trained using labelled data', 'there are many metrics available to represent the performance of trained models such as accuracy receiver operating characteristic roc confusion matrix precision recall and f1 score can be used to evaluate classification algorithms mean absolute error mae root mean squared error relative absolute error relative squared error mean zero one error and coefficient of determination are common metrics for regression models evaluation metrics for clustering models include average distance to cluster centre average distance to other centre number of points and maximal distance to cluster centre', 'iso and iec maintain terminology databases for use in standardization at the following addresses iso online browsing platform available at iec electropedia available at 3.1 model development and use 3.1.1 classification model machine learning machine learning model whose expected output for given input is one or more classes 3.1.2 regression model machine learning machine learning model whose expected output for given input is continuous variable 3.1.3 generalization machine learning ability of trained model to make correct predictions on previously unseen input data note to entry machine learning model that generalizes well is one that has acceptable prediction accuracies using previously unseen input data']"
0,49,0_layers_neuron_nns_cnns,"['layers', 'neuron', 'nns', 'cnns', 'neural', 'inputs', 'convolution', 'pooling', 'networks', 'gate']","['two adjacent layers are typically fully connected in that each neuron in one layer has connection to each neuron in the subsequent layer', '6.5.3.2.4 convolutional neural network convolutional neural networks cnns are type of nn that includes at least one layer of convolution to filter useful information from inputs', 'as opposed to rnns each neuron placed on given layer of the cnn is connected to neurons from previous layer only and is not fed with information on its previous state']"
1,34,1_ml_neural_algorithms_function,"['ml', 'neural', 'algorithms', 'function', 'θ0', 'components', 'categories', 'model', 'positive', 'intercept']","['the relationship between ml algorithms and ml models can be illustrated by considering the solving of univariate linear function θ0 θ1x where is an output or result is an input θ0 is an intercept the value of where x=0 and θ1 is weight', '6.5.3 categories of ml algorithms 6.5.3.1 general the choice of the ml algorithm defines the computational structure of the ml model and its training approach', ""3.3.5 unlabelled property of sample that does not include target variable abbreviated terms ai artificial intelligence api application programming interface auc area under the curve bm boltzmann machines capsnet capsule neural network cg conjugate gradient cnn convolutional neural network dbn deep belief networks dcnn deep convolutional neural network ffnn feed forward neural network fnr false negative rate fpr false positive rate gru gated recurrent unit lstm long short-term memory mae mean absolute error mdp markov decision process ml machine learning nn neural network nnef neural network exchange format npv negative predictive value onnx open neural network exchange pca principal component analysis phi personal or protected health information pii personally identifiable information ppv positive predictive value rest representational state transfer rnn recurrent neural network roc receiver operating characteristics sgd stochastic gradient descent svm support vector machine tnr true negative rate tpr true positive rate overview iso/iec defines ml as the process of optimising model parameters through computational techniques such that the model 's behaviour reflects the data or experience""]"
2,29,2_reinforcement_reward_agent_learning,"['reinforcement', 'reward', 'agent', 'learning', 'structured', 'game', 'policies', 'interact', 'planning', 'maximise']","['control is the application of reinforcement machine learning to interact with an environment', '7.6 reinforcement machine learning reinforcement learning differs from the other approaches as its principle is that the model is initialised at state an action is taken reward for the action is determined and the model is advanced to new state that attempts to maximise the reward', 'reinforcement machine learning can also be combined with supervised machine learning training on labelled data is used to initialise the model and reinforcement is used to determine subsequent policies the agent uses to take actions']"
3,28,3_bayesian_event_networks_causality,"['bayesian', 'event', 'networks', 'causality', 'diagnosis', 'resources', 'cases', 'knowledge', 'expense', 'faults']","['various bayesian statistical methods exist which can be used in conjunction with bayesian networks to determine causality or perform data analysis', '6.5.3.3 bayesian network bayesian networks are graphical models used for generating predictions on the dependencies between variables', 'bayesian networks rely on bayesian probability the probability of an event is considered to be the degree of belief in that event']"
4,26,4_labelled_labels_label_labelling,"['labelled', 'labels', 'label', 'labelling', 'unlabelled', 'data', 'samples', 'pseudo', 'training', 'supervised']","['labelled training data allows the ml algorithm to identify statistical relationships between input variables and the target variable', 'in such cases the corresponding data will include one or more labels or target variables that represent ground truth about the data record or sample', 'data used to train supervised machine learning models will include one or more labels or target variables that represent truth about the data record or sample']"
5,25,5_tpr_score_auc_precision,"['tpr', 'score', 'auc', 'precision', 'kappa', 'fpr', 'roc', 'rater', 'sensitivity', 'reliability']","['however this metric is typically less informative than the precision and recall pair or the f1 score', '6.5.5.3 f1 score f1 score expresses model performance through combination of recall and precision', 'key fpr tpr auc roc figure receiver operating characteristics curve the area under the roc curve auc is measure of performance across all classification thresholds']"
6,24,6_likelihood_optimisation_ml_methods,"['likelihood', 'optimisation', 'ml', 'methods', 'estimation', 'parameters', 'polynomial', 'fitting', 'hidden', 'algorithm']","['it consists in an alternation between expectation steps estimate the hidden variables based on current parameters and maximisation steps re-estimate the parameters to optimise the likelihood of the data given the current value of the hidden variables up to convergence', '6.5.4 ml optimisation methods 6.5.4.1 general ml optimisation methods are used to fit an ml model to ml data', '6.5.4.7 maximum likelihood estimation maximum likelihood estimation is method for estimating the parameters of probability distribution by maximising the likelihood function']"
7,22,7_gradient_descent_hessian_adaptive,"['gradient', 'descent', 'hessian', 'adaptive', 'surface', 'sgd', 'matrix', 'methods', 'iteration', 'stochastic']","['6.5.4.3 newton method newton method uses the first order derivative gradient and second order derivative matrix otherwise known as the hessian matrix to approximate the objective function with quadratic function', '6.5.4.2 gradient descent methods gradient descent is an iterative technique to find the minimum of function while feeding the whole dataset as single batch the parameters are updated step by step in the same direction as the first- order derivative gradient of the function', '6.5.4.4 conjugate gradient the conjugate gradient cg method calculates the hessian vector product without directly calculating the hessian matrix as in newton method']"
8,21,8_validation_training_testing_folds,"['validation', 'training', 'testing', 'folds', 'datasets', 'cross', 'processes', 'needs', 'model', 'reliable']","['dataset splitting ml models need training data but also validation data for model selection and test data for model evaluation', 'validation and test data are both used with statistical performance measures which are discussed in 6.5.5 but their uses differ validation data is used to tune the hyperparameters whereas test data is about evaluating the model', 'the distribution of production data can differ from that of training validation and test dataset']"
9,20,9_features_engineering_selecting_type,"['features', 'engineering', 'selecting', 'type', 'dataset', 'textual', 'granularity', 'categorical', 'dimensionality', 'encoding']","['feature engineering is the process of selecting characterizing and optimising features for use in an ml model', 'see also 6.2.6 feature selection the foundation of feature selection is that data can contain features that are either redundant or irrelevant and therefore can be removed', 'examples of feature engineering include encoding for efficiency and ease-of-use textual and categorical features are often converted to numeric identifiers data type conversion it can be necessary to convert the feature data type to meet the requirements of given model \ufeff\x08 dimensionality reduction high dimensionality in the input data can be troublesome for some ml algorithms']"
10,18,10_margin_svm_hyperplane_soft,"['margin', 'svm', 'hyperplane', 'soft', 'classifiers', 'vectors', 'violations', 'closest', 'classifying', 'objective']","['soft- margin classifiers attempt to achieve maximal margin while limiting margin violations', 'the points that are closest to the boundary are called support vectors. the orthogonal distance between support vectors and the hyperplane is half of the margin of svm', 'in svm regression the objective is to fit as many data instances as possible inside the margin while limiting margin violations i.e']"
11,18,11_flow_data_statements_process,"['flow', 'data', 'statements', 'process', 'supervised', 'insurance', 'vehicle', 'sensor', 'descriptions', 'maintenance']","['within the data flow described in a.2.2.3 data flow the following example data use statement can be formulated example input device sensor data from engine mounted temperature sensors is used by the ml model to predict failure of components and improve engine performance and maintenance', 'within the data flow described in a.2.2.2 data flow the following example data use statement can be formulated example model training process uses aggregated and labelled sensor data from onboard vehicle cameras to train the object recognition ml model', 'within the data flow described in a.2.2.1 data flow the following example data use statement can be formulated example data preparation tools use anonymized financial data from home insurance claims to improve and prepare the acquired data for ml model development']"
12,17,12_rnns_lstm_memory_long,"['rnns', 'lstm', 'memory', 'long', 'gate', 'lstms', 'backpropagation', 'sequential', 'gradient', 'networks']","['an lstm is designed for learning long-term dependencies and has an architecture based on combination of neurons with cell which has the memory capability an input gate an output gate and forget gate', 'common types of rnns include long short-term memory lstm and gated recurrent unit gru networks simpler variant of lstm', '6.5.3.2.3.2 long short-term memory networks long short-term memory lstm networks are form of rnn designed for problems that require remembering information with both longer and shorter time differences making them suitable to learn long-term connections']"
13,17,13_imputation_missing_cleaning_entries,"['imputation', 'missing', 'cleaning', 'entries', 'columns', 'outliers', 'deck', 'attribute', 'dataset', 'imputed']","['common data cleaning processes include removing duplicate entries filling in missing data and dealing with incorrect data and outliers', 'multiple imputation reflects uncertainty about missing values from an imputation model generating the targeted value by considering several imputed values randomly selected from slightly different models', 'imputation data imputation refers to cleaning process using substituted values to replace missing data']"
14,16,14_mobile_complexity_computing_performance,"['mobile', 'complexity', 'computing', 'performance', 'optimisation', 'hardware', 'workloads', 'energy', 'efficient', 'compressing']","['optimisation the model can be optimised for target platform such as by adjusting data types from exact to approximate or from machine independent to those natively supported on the target platform e.g', 'compressing weights or squeezing the architecture can reduce the model complexity by significant factor while maintaining almost identical performance', 'the runtime impact and energy consumption can be minimised and in some cases the reduction even enables the nn to be run in real-time on mobile devices without relying on cloud services']"
15,16,15_overfitting_training_underfitting_generalize,"['overfitting', 'training', 'underfitting', 'generalize', 'note', 'overfitted', 'samples', 'outliers', 'features', 'leakage']","['underfitting can occur when features are poorly selected or there are insufficient model parameters to properly learn on large number of training samples', '3.1.4 overfitting machine learning creating model which fits the training data too precisely and fails to generalize on new data note to entry overfitting can occur because the trained model has learned from non-essential features in the training data i.e', '3.1.5 underfitting machine learning creating model that does not fit the training data closely enough and produces incorrect predictions on new data note to entry underfitting can occur when features are poorly selected insufficient training time or when the model is too simple to learn from large training data due to limited model capacity i.e']"
16,15,16_retraining_retrained_drift_continuous,"['retraining', 'retrained', 'drift', 'continuous', 'model', 'training', 'changes', 'leveraging', 'evolving', 'updating']","['in cases where the model needs to adapt dynamically to new patterns in the production data the model can be continuously retrained by leveraging information gained from production data', 'over time the production data distribution can drift which can require the model to be retrained on new data', 'continuous learning is special case of retraining in that the model performance is continuously evolving resulting from on-going training of the model with production data']"
17,15,17_references_content_exemplary_clauses,"['references', 'content', 'exemplary', 'clauses', 'amendments', 'reader', 'depth', 'section', 'constitutes', 'cited']","['for dated references only the edition cited applies', 'for undated references the latest edition of the referenced document including any amendments applies', 'normative references the following documents are referred to in the text in such way that some or all of their content constitutes requirements of this document']"
18,15,18_acquisition_identification_sources_pii,"['acquisition', 'identification', 'sources', 'pii', 'dataset', 'association', 'vendors', 'store', 'transactional', 'forecasting']","['dataset composition dataset composition refers to the selection or compilation of acquired data from various data sources into single dataset', 'this also includes de-identification although the acquired data can have been de-identified earlier additional de- identification can be required because of data processing e.g', 'the data sources are identified and the required data is acquired e.g']"
19,14,19_figure_supervised_illustrated_learning,"['figure', 'supervised', 'illustrated', 'learning', 'pipeline', 'machine', 'processes', 'programs', 'layered', 'development']","['this process is illustrated in figure', 'the process of training is however similar to the supervised machine learning process shown in figure', 'key progress to invoke code operate on/use figure example supervised machine learning process based on the ml pipeline in figure in the top model layer are the process steps for system using supervised learning']"
20,14,20_evaluation_metrics_validation_risks,"['evaluation', 'metrics', 'validation', 'risks', 'mallow', 'optimized', 'cp', 'vital', 'conformity', 'assessed']","['8.5 verification and validation model evaluation model evaluation is the process of comparing the predictions made by the model on test data to the actual labels in the data', 'model evaluation is when the model is tested using evaluation metrics in order to assess its performance and conformity', 'model evaluation applies evaluation metrics on test data to assess the performance of the trained model']"
21,14,21_accuracy_precision_detected_counts,"['accuracy', 'precision', 'detected', 'counts', 'definitions', 'confusion', 'classifications', 'negatives', 'recall', 'matrix']","['true or false multi-class i.e', 'in multi-class classification it can be understood either as per- class accuracy or as model accuracy', 'in multi-class classification the definitions are applied in turn to all classes and precision refers to some combination of precision for each class']"
22,13,22_pipeline_processes_tasks_task,"['pipeline', 'processes', 'tasks', 'task', 'describes', 'reach', 'diversity', 'deploying', 'goals', 'developing']","['clause in this document describes an ml pipeline the processes involved in developing deploying and operating an ml model', 'figure typical transfer learning processes machine learning pipeline 8.1 general to reach particular application goal using ml an ml model is created evaluated and put into use', '8.8 example machine learning process based on ml pipeline the ml pipeline processes can be applied to different learning techniques and ml model development']"
23,12,23_clustering_anomaly_instances_outliers,"['clustering', 'anomaly', 'instances', 'outliers', 'applications', 'organizing', 'fraud', 'sorting', 'centroid', 'detect']","['unlike classification tasks the classes are not predefined in clustering tasks but are determined as part of the clustering process', '6.2.5 anomaly detection anomaly detection comprise identifying input data instances that do not conform to an expected pattern', '6.2.4 clustering clustering tasks comprise grouping input data instances']"
24,12,24_hyperparameters_tuning_hyperparameter_validation,"['hyperparameters', 'tuning', 'hyperparameter', 'validation', 'selection', 'grid', 'automate', 'guided', 'algorithms', 'width']","['it is unrelated to validation data which is used for tuning the hyperparameters during the design and development phase', 'model selection also known as hyperparameter tuning model selection is the process of using the validation dataset to assess and optimise hyperparameters to determine which values provide the best results in order to select the best model', 'this step is called model selection or hyperparameter tuning']"
25,11,25_environment_deployment_development_packaging,"['environment', 'deployment', 'development', 'packaging', 'python', 'servers', 'virtual', 'interpreter', 'deploys', 'containers']","['8.6 model deployment once an ml model is trained and evaluated it needs to be deployed into an operating environment where it can be used to make predictions on production data', 'the trained model can then be deployed on any run-time environment that has corresponding abstraction layer such as an interpreter or just-in-time compiler', 'the run-time environment of the model can be of lower-level than its development environment']"
26,11,26_tools_dimension_task_dependency,"['tools', 'dimension', 'task', 'dependency', 'development', 'steps', 'horizontal', 'distinction', 'phases', 'conduct']","['model development and use in turn have dependency on software tools and techniques and data', 'in the middle software tools and techniques layer are the tools and data processing elements required to conduct the process steps', 'while the horizontal dimension corresponds to the three stages the vertical dimension indicates whether the depicted components and processes are associated to data model or tools']"
27,10,27_framework_ecosystem_terms_organizations,"['framework', 'ecosystem', 'terms', 'organizations', 'definitions', 'proprietary', '17_23053_modified', 'technologies', 'engineered', 'forecasts']","['the framework describes the system components and their functions in the ai ecosystem', 'this document is applicable to all types and sizes of organizations including public and private companies government entities and not-for-profit organizations that are implementing or using ai systems', 'international standard framework for artificial intelligence ai systems using machine learning ml scope this document establishes an artificial intelligence ai and machine learning ml framework for describing generic ai system using ml technology']"
28,10,28_dimensionality_attributes_features_reduce,"['dimensionality', 'attributes', 'features', 'reduce', 'variances', 'promote', 'groups', 'goods', 'exploration', 'retaining']","['dimensionality reduction is also useful for data exploration and model analysis', '6.2.6 dimensionality reduction dimensionality reduction consists of reducing the number of attributes or dimensions per sample while retaining most of the useful information', 'for high dimensional data it is often desirable to reduce the dimensionality by projecting the data to lower dimensional subspace which captures the essence of the data identification of correlations within set of measurements of several variables image inpainting of damaged or otherwise impaired pictures market basket analysis where groups of goods which are usually purchased or sold together are identified']"
29,9,29_production_predicting_mode_regression,"['production', 'predicting', 'mode', 'regression', 'prostate', 'projected', 'observations', 'antigen', 'models', 'streams']","['running the model on production data results in the system making predictions and making decisions based on the output of the model', 'ml models are used in batch mode with fixed sets of production data or in continuous mode on real-time streams of production data', 'use cases for regression include predicting stock market price predicting the age of viewer of streaming videos predicting the amount of prostate-specific antigen in the body based on different clinical measurements']"
30,9,30_furniture_numbers_width_classification,"['furniture', 'numbers', 'width', 'classification', 'objects', 'predict', 'images', 'recognizing', 'cat', 'handwritten']","['for example model that has learned to recognize furniture and objects can be fine-tuned to identify scenery e.g', 'for example knowledge gained from recognizing house numbers in street view can be used to recognize handwritten numbers', 'for example an ml classification model can predict the species of flower when provided with data that specifies the sepal length and width and the petal length and width image classification']"
31,8,31_normalisation_noise_features_skew,"['normalisation', 'noise', 'features', 'skew', 'decimal', 'values', 'scaled', 'normal', 'deviation', 'curse']","['normalisation and scaling significant differences in the range of numerical features in dataset can cause the features to be not comparable when training an ml model', 'datasets that have large number of features can encounter the curse of dimensionality where certain features introduce noise into the model or skew the model predictions inappropriately reduce overfitting of the model', 'examples for data normalisation techniques are min-max normalisation linear transformation of the data to fit within minimum and maximum values often zero and one z-score normalisation data is scaled based on the mean and standard deviation decimal scaling moving the decimal point of the attribute values']"
32,8,32_training_statistical_dataset_properties,"['training', 'statistical', 'dataset', 'properties', 'models', 'partitioned', 'derived', 'diagram', 'gain', 'corresponds']","['model training an ml model is trained by iterating over the training data to establish constants or weights for each parameter in the model', '6.4 data figure is rake diagram showing that the data concept is partitioned into four mutually exclusive categories training dataset used to estimate the parameters of candidate models validation dataset also known as development dataset depending on the ai field e.g', 'the model is populated also known as trained to represent the relevant statistical properties of the training data']"
33,8,33_supervised_semi_self_learning,"['supervised', 'semi', 'self', 'learning', 'unlabelled', 'warrant', 'discussion', 'ensemble', 'representations', 'separate']","['7.5 self-supervised machine learning self-supervised machine learning is an approach for training on unlabelled data using algorithms that normally belong to supervised machine learning', '7.4 semi-supervised machine learning semi-supervised machine learning is defined as machine learning that makes use of both labelled and unlabelled data during training', 'note that self-supervised machine learning is unrelated to self-training which is specific method for semi-supervised machine learning']"
