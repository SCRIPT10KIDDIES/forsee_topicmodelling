Topic,Count,Name,Representation,Representative_Docs
-1,87,-1_risk_management_table_objectives,"['risk', 'management', 'table', 'objectives', 'development', 'level', 'assessment', 'likelihood', 'automation', 'processes']","['table continued table continued \ufeff\x08 principle description as given in iso 31000:2018 clause implications for the development and use of ai human and cultural factors human behaviour and culture significantly influence all aspects of risk management at each level and stage', 'annex informative risk management and ai system life cycle table c.1 shows an example of mapping between the risk management processes and an ai system life cycle as defined in iso/iec 22989:2022', 'table c.1 risk management and ai system life cycle ai risk manage- ment framework clause ai risk management process clause risk management ai system life cycle scope context and criteria risk assessment risk treatment monitoring and review recording and re- porting organizational level activities related to risk management governing body sets directions for ai risk man- agement']"
0,32,0_guidance_31000_roles_references,"['guidance', '31000', 'roles', 'references', 'internal', 'establishing', 'organization', 'exclu', 'consultation', 'structure']","['table consideration when establishing the internal context of an organization generic guidance provided by iso 31000:2018 5.4.1 additional guidance for organizations engaged in ai organizations should consider at least the follow- ing elements of their internal context organizations should additionally consider but not exclu- sively the following elements vision mission and values no specific guidance beyond iso 31000:2018 governance organizational structure roles and accountabilities no specific guidance beyond iso 31000:2018 strategy objectives and policies no specific guidance beyond iso 31000:2018 the organization culture the effect that an ai system can have on the organization culture by shifting and introducing new responsibilities roles and tasks', 'the guidance provided in iso 31000:2018 5.1 applies', '\ufeff\x08 generic guidance provided by iso 31000:2018 5.4.1 additional guidance for organizations engaged in ai organizations should consider at least the following elements of their external context organizations should additionally consider but not exclusively the following elements guidance beyond iso 31000:2018']"
1,21,1_management_guidance_risks_considerations,"['management', 'guidance', 'risks', 'considerations', 'organizations', 'development', 'processes', 'criteria', 'strategic', 'stakeholders']","['in addition to the guidance provided in iso 31000:2018 5.2 the following applies due to the particular importance of trust and accountability related to the development and use of ai top management should consider how policies and statements related to ai risks and risk management are communicated to stakeholders', 'in addition to the guidance provided in iso 31000:2018 6.3.1 for organizations using ai the scope of the ai risk management the context of the ai risk management process and the criteria to evaluate the significance of risk to support decision-making processes should be extended to identify where ai systems are being developed or used in the organization', 'in addition to the guidance provided in iso 31000:2018 6.3.4 table provides additional guidelines on factors to be considered when defining risk criteria \ufeff\x08 table additional guidance when defining risk criteria considerations for defining risk criteria as provid- ed in iso 31000:2018 6.3.4 additional considerations in the context of the development and use of ai systems the nature and type of uncertainties that can affect outcomes and objectives both tangible and intangible organizations should take reasonable steps to understand uncertainty in all parts of the ai system including the utilized data software mathematical models physical extension and human-in-the-loop aspects of the system such as any related human activity during data collection and labelling']"
2,19,2_resources_complexity_interconnections_dependencies,"['resources', 'complexity', 'interconnections', 'dependencies', 'interdependencies', 'network', 'environments', 'technologies', 'increasingly', 'latency']","['when an ai system requires remote processing and storage network errors bandwidth restrictions and increased latency due to the limited and shared nature of network resources', 'certain ai technologies like ml are specifically suited to handle complex environments and are therefore often used for systems used for complex environments like automated driving', 'the use of ai systems can result in changes to the number of human resources needed to realize certain capability or in variation of the type of resources needed for instance deskilling or loss of expertise where human decision-making is increasingly supported by ai systems']"
3,17,3_stakeholders_stakeholder_perceptions_expectations,"['stakeholders', 'stakeholder', 'perceptions', 'expectations', 'failure', 'needs', 'capabilities', 'values', 'development', 'assess']","['stakeholder needs and expectations can be satisfied by specific ai systems', 'external stakeholders relationships perceptions values needs and expectations stakeholder perceptions which can be affected by issues such as lack of transparency also referred to as opaqueness of ai systems or biased ai systems', 'relationships with internal stakeholders taking into account their perceptions and values stakeholder perception which can be affected by issues such as lack of transparency of ai systems or biased ai systems']"
4,16,4_data_privacy_protecting_information,"['data', 'privacy', 'protecting', 'information', 'access', 'operations', 'misuse', 'disclosures', 'discrimination', 'freedoms']","['stakeholders can help in the identification of risks regarding the data collection the processing operations the source and type of data and the use of the data for particular situations or where the data subjects can be outliers', 'for ai systems protecting privacy includes protecting the data used for building and operating the ai system ensuring that the ai system can not be used to give unwarranted access to its data and protecting access to models personalized for an individual or that can be used to infer information or characteristics of similar individuals', 'note data protection impact assessment see iso/iec 29134:2017 often referred to as privacy impact assessment is useful tool for managing the risks related to the use of personal data during the collection of data training of an ai system and use of an ai system']"
5,16,5_accountability_reports_stakeholders_entity,"['accountability', 'reports', 'stakeholders', 'entity', 'applications', 'regulators', 'cases', 'standards', 'investigations', 'leverage']","['care should be taken to consider list of stakeholders including but not limited to the organization itself customers partners and third parties suppliers end users regulators civil organizations individuals affected communities societies', 'a.2 accountability accountability refers both to characteristic of organizations and to system property organizational accountability means that an organization takes responsibility for its decisions and actions by explaining them and being answerable for them to the governing body to legal authorities and more broadly to stakeholders', 'events can be identified through one or more of the following methods and sources published standards \ufeff\x08 published technical specifications published technical reports published scientific papers market data on similar systems or applications already in use reports of incidents on similar systems or applications already in use field trials usability studies the results of appropriate investigations stakeholder reports interviews with and reports from internal or external experts simulations']"
6,15,6_management_framework_risk_clause,"['management', 'framework', 'risk', 'clause', 'processes', 'activities', 'assist', 'assessing', 'information', 'organizational']","['additional guidance for the risk management principles framework and processes an organization can implement is provided by this document', 'clause framework the purpose of the risk management framework is to assist the organization in integrating risk management into significant activities and functions', 'framework 5.1 general the purpose of the risk management framework is to assist the organization in integrating risk management into significant activities and functions']"
7,15,7_consequences_societies_repair_reputation,"['consequences', 'societies', 'repair', 'reputation', 'responsibility', 'organizations', 'environmental', 'recruitment', 'litigations', 'incident']","['note consequences to individuals and societies usually can also lead to consequences to the organization', 'consequences to organizations can include but are not limited to investigation and repair time work time gained and lost opportunities gained or lost threats to health or safety of individuals financial costs of specific skills to repair the damage employee recruitment satisfaction and retention image reputation and goodwill penalties and fines customer litigations', 'the organization can consider both when assessing the consequences to the organization to individuals and to societies']"
8,14,8_ml_robustness_trained_behaviour,"['ml', 'robustness', 'trained', 'behaviour', 'safety', 'models', 'data', 'inspection', 'nonlinear', 'vehicles']","['an ml model can have behaviour that is difficult to understand by inspection of the model or the algorithm used to train it especially in the case of deep learning', 'the behaviour of ml systems is critically dependent not just on the algorithms in use but also on the data on which the ml models are trained', 'in the context of ai and in particular with regard to ai systems based on ml approaches several new issues such as data poisoning adversarial attacks and model stealing as described in iso/iec tr 24028:2020 should be considered beyond classical information and system security concerns']"
9,14,9_31000_guidance_risk_consistent,"['31000', 'guidance', 'risk', 'consistent', 'management', 'standards', 'iterative', 'proportionate', 'deviation', 'capacity']","['6.4 risk assessment 6.4.1 general the guidance provided in iso 31000:2018 6.4.1 applies', '6.4.3 risk analysis 6.4.3.1 general the guidance provided in iso 31000:2018 6.4.3 applies', 'risk management process 6.1 general the guidance provided in iso 31000:2018 6.1 applies']"
10,13,10_risk_tem_sys_cess,"['risk', 'tem', 'sys', 'cess', 'reports', 'retire', 'cific', 'adjustments', 'spe', 'assessed']","['verification and val- idation \ufeff\x08 ai risk manage- ment framework clause ai risk management process clause risk management ai system life cycle scope context and criteria risk assessment risk treatment monitoring and review recording and re- porting deployment governing body continually re-as- sesses the ob- jectives and the feasibility of the system based on received feedback reports', 'the ai system risk management pro- cess and the sys- tem risk criteria are established through customiza- tion of the organiza- tion risk manage- ment framework', 'the ai system risk management pro- cess and the sys- tem risk criteria are re-evaluated against any poten- tial changes to the specific purpose and scope of the ai system outcome of operation monitor- ing and new regula- tory requirements the list of existing risk sources specif- ic to the ai system are examined for relevance and any possible gaps']"
11,12,11_treatment_risk_assessed_plans,"['treatment', 'risk', 'assessed', 'plans', 'implementing', 'configura', 'ailed', 'det', 'adjusted', 'selection']","['the risk treat- ment plan is po- tentially updated due to configura- tion changes and implemented', 'once the risk treatment plan has been documented the risk treatment measures selected in 6.5.2 should be implemented', 'the risk treat- ment plan is po- tentially updated']"
12,12,12_transparency_explainability_technologies_characteristics,"['transparency', 'explainability', 'technologies', 'characteristics', 'stakeholders', 'collaborate', 'topologies', 'capital', 'diversity', 'confidentiality']","['capital time people intellectual property processes systems and technologies the additional risks to organizational knowledge related to transparency and explainability of ai systems', 'b.3 lack of transparency and explainability transparency is about communicating appropriate activities and decisions of an organization e.g', 'a.12 transparency and explainability transparency relates both to characteristics of an organization operating ai systems and to those systems themselves']"
13,12,13_assets_tangible_intangible_impacts,"['assets', 'tangible', 'intangible', 'impacts', 'values', 'assessing', 'equity', 'dignity', 'valuation', 'ethic']","['assets of and their value to communities and societies tangible assets can include the environment intangible assets are likely more values based such as socio-cultural beliefs community knowledge educational access and equity', 'assets of and their value to individuals tangible assets can include an individual personal data intangible assets can include privacy health and safety of an individual', 'additionally in relation to the development and use of ai assets should be considered in the context of elements including but not limited to the following assets of and their value to the organization tangible assets can include data models and the ai system itself']"
14,12,14_expertise_guidelines_standards_development,"['expertise', 'guidelines', 'standards', 'development', 'disciplinary', 'ecosystem', 'legislation', 'specification', 'skillsets', 'national']","['standards guidelines and models adopted by the organization any additional international regional national and local standards and guidelines that are imposed by the use of ai systems', 'selection of dedicated specialists with inter-disciplinary skillsets and expertise in assessing developing and deploying ai systems is needed', 'organizations engaged in the design development or deployment of ai systems or system components or any combination of these should monitor the ai ecosystem for performance successes shortcomings and lessons learned and maintain awareness of new ai research findings and techniques opportunities for improvement']"
15,11,15_risk_residual_risks_options,"['risk', 'residual', 'risks', 'options', 'management', 'assess', 'likelihood', 'outcomes', 'avoiding', 'triggers']","['risk treatment options defined by the organization should be designed to reduce negative consequences of risks to an acceptable level and to increase the likelihood that positive outcomes can be achieved', 'if the required reduction of negative outcomes can not be achieved by applying different risk treatment options the organization should carry out risk-benefit analysis for the residual risks', 'in accordance with iso 31000:2018 6.5.2 the organization should consider avoiding the risk by deciding not to start or continue with the activity that gives rise to the risk taking or increasing the risk in order to pursue an opportunity removing the risk source changing the likelihood changing the consequences sharing the risk for instance through contracts or buying insurance retaining the risk by informed decision']"
16,11,16_test_training_quality_behaviour,"['test', 'training', 'quality', 'behaviour', 'predictive', 'features', 'sourced', 'ownership', 'datasets', 'company']","['therefore possible effects on ai characteristics include data quality the quality of training and test data directly affects the functionality of the system', 'the training test and production data should be fit to the intended behaviour with respect to data type and quality', 'a.4 availability and quality of training and test data ai systems based on ml need training and test data in order to train and verify the systems for the intended behaviour']"
17,10,17_bias_fairness_groups_unfair,"['bias', 'fairness', 'groups', 'unfair', 'unfairness', 'societal', 'cultural', 'rights', 'development', 'outcomes']","['impact analyses for individuals should determine the degree to which an individual can be affected by the development or use of ai by the organization or both', 'they should consider elements including but not limited to the following scope of societal impact how broad is the reach of the ai system into different populations including who the system is being used by or designed for for instance governmental use can potentially impact societies more than private use how an ai system affects social and cultural values held by various affected groups including specific ways that the ai system amplifies or reduces pre-existing patterns of harm to different social groups', 'they should consider elements including but not limited to the following types of data used from the individuals intended impact of the development or use of ai potential bias impact to an individual potential impact on fundamental rights that can result in material and non-material damage to an individual potential fairness impact to an individual safety of an individual protections and mitigating controls around unwanted bias and unfairness \ufeff\x08 jurisdictional and cultural environment of the individual which can affect how relative impact is determined']"
18,10,18_sources_risks_learning_organization,"['sources', 'risks', 'learning', 'organization', 'subfields', 'prioritized', 'mitigate', 'fed', 'capacity', 'informative']","['6.4.2.6 identification of consequences as part of ai risk assessment the organization should identify risk sources events or outcomes that can lead to risks', '6.4.2.3 identification of risk sources the organization should identify list of risk sources related to the development or use of ai or both within the defined scope', '\ufeff\x08 annex informative risk sources b.1 general when identifying risks of ai systems various risks sources should be taken into account depending on the nature of the system under consideration and its application context']"
19,9,19_environment_environmental_complexity_situations,"['environment', 'environmental', 'complexity', 'situations', 'consideration', 'extensive', 'forecast', 'encounter', 'determining', 'controlled']","['b.2 complexity of environment the complexity of the environment of an ai system determines the range of potential situations an ai system is intended to support in its operational context', 'special consideration should be given to determining the degree to which the ai system environment is understood complete understanding of environment that is only possible for simple predictable or controlled environments such that the ai system is prepared for all possible states of the environment that it can encounter allows for better risk control', 'in case of partial understanding due to high complexity or uncertainty of the environment such that the ai system can not forecast all possible states of the environment for instance autonomous driving it can not be assumed that all relevant situations are considered']"
20,9,20_memory_hardware_cells_circuits,"['memory', 'hardware', 'cells', 'circuits', 'readiness', 'oscillators', 'radiation', 'faults', 'redundancy', 'lines']","['b.8 technology readiness technology readiness indicates how mature given technology is in given application context', 'soft errors such as unwanted temporary state changes of memory cells or logic components mostly caused by high energy radiation', 'examples are short circuits or interruptions of single or multiple memory cells defective bus lines drifting oscillators stuck-at faults or parasitic oscillations at the inputs or outputs of integrated circuits']"
21,8,21_maintainability_validation_requirements_regressions,"['maintainability', 'validation', 'requirements', 'regressions', 'revision', 'reliability', 'maintenance', 'developer', 'deterioration', 'defects']","['an ai system can replace an existing system and in such case an assessment of the risk benefits and risk transfers of an ai system versus the existing system can be undertaken considering safety environmental social technical and financial issues associated with the implementation of the ai system', 'maintenance update and revision an ai system no longer supported or maintained by the developer but still in use can present long-term risks or liability to the developing organization', 'verification and validation an inadequate verification and validation process for releasing updated versions of the ai system can lead to accidental regressions or unintended deterioration or degradation in quality reliability or safety']"
22,8,22_governing_tives_objec_decommissioned,"['governing', 'tives', 'objec', 'decommissioned', 'sesses', 'reports', 'feasi', 'stakehold', 'seeks', 'layer']","['design and develop- ment governing body continually re-as- sesses the objec- tives the efficacy and the feasibili- ty of the system based on received feedback reports', 'continuous valida- tion re-evaluation governing body re-examines the ai system objec- tives and their relation to the organization and the stakeholders principles and val- ues based on the anal- ysis determines whether the ai system is feasible', 'governing body re-examines the ai system objec- tives based on the analysis de- termines wheth- er the ai system retirement or replacement is feasible']"
23,8,23_treat_catalogue_layers_tinue,"['treat', 'catalogue', 'layers', 'tinue', 'criteria', 'urements', 'risks', 'mitigation', 'assessment', 'techniques']","['the risk assess- ment is performed continuously po- tentially on multi- ple layers', 'the risk treat- ment and the re- maining risks assessment con- tinue until the established risk criteria are met', 'the risk treat- ment and the re- maining risks assessment con- tinue until the established risk criteria are met']"
