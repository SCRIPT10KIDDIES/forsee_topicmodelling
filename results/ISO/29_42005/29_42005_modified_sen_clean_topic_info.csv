Topic,Count,Name,Representation,Representative_Docs
-1,109,-1_impact_benefits_organization_impacts,"['impact', 'benefits', 'organization', 'impacts', 'harms', 'reporting', 'assessments', 'misuse', 'adverse', 'accountability']","['6.8 actual and reasonably foreseeable impacts 6.8.1 general for the relevant interested parties that are identified in 6.7.2 the reasonably foreseeable benefits and harms should be identified', '5.10.4 reporting of ai system impact assessment to relevant interested parties can include actual or reasonably foreseeable impact information related to the intended ai system use cases as well as other potentially beneficial uses and reasonably foreseeable misuses at least at broad level as many dimensions of identified impacts as appropriate including as many of the types of impacts outlined in 6.8 as reasonably possible measures taken to address the identified impacts', 'table e.18 benefits and harms benefits harms accountability description of reasonably foreseeable benefits regarding accountability description of reasonably foreseeable harms regarding accountability transparency description of reasonably foreseeable benefits regarding transparency description of reasonably foreseeable harms regarding transparency fairness and dis- crimination description of reasonably foreseeable benefits regarding fairness and discrimination description of reasonably foreseeable harms regarding fairness and discrimination privacy description of reasonably foreseeable benefits regarding privacy description of reasonably foreseeable harms regarding privacy reliability description of reasonably foreseeable benefits regarding reliability description of reasonably foreseeable benefits regarding reliability safety description of reasonably foreseeable benefits regarding safety description of reasonably foreseeable benefits regarding safety explainability description of reasonably foreseeable benefits regarding explainability description of reasonably foreseeable benefits regarding explainability environmental im- pact description of reasonably foreseeable benefits regarding environmental impact description of reasonably foreseeable benefits regarding environmental impact e.2.8 ai system failures and reasonably foreseeable misuse e.2.8.1 impact of ai system failure for each of the interested parties identified in e.2.6 includes information on the impact of ai system failure table e.19']"
0,24,0_ensure_resources_coordination_components,"['ensure', 'resources', 'coordination', 'components', 'organization', 'considerations', 'applications', 'reviewers', 'development', 'limitations']","['include information about the intended end user of the ai system where and when the ai system can be used', 'when documenting the purpose of the ai system the organization should consider the following the end user or primary customer of the ai system how the ai system addresses user needs the value proposition of the ai system any trade-offs made in relation to the decision to use the ai system', 'intended uses can be detailed by use cases or scenario which can include what the ai system is designed to do or achieve for specific groups of end users or customers where and when end users can use the ai system whether there are limitations on the ai system including temporal limitations such as the time period the ai system is supposed to be in operation']"
1,22,1_tionality_func_edition_capability,"['tionality', 'func', 'edition', 'capability', 'references', 'aspects', 'amendments', 'deployer', 'granularity', 'deemed']","['refer to 6.5.4 and 6.5.5', 'refer to 6.3.3', 'refer to 6.4.2']"
2,21,2_table_capabilities_functionalities_identification,"['table', 'capabilities', 'functionalities', 'identification', 'dependencies', 'information', 'approval', 'purpose', 'assessment', 'revision']","['table e.6 description of ai system dependencies on other systems information on potential dependencies of the ai system under assessment to other systems and their functionalities and capabilities e.2.2.4 ai system purpose includes description of the purpose of the ai system why it is being developed or used the value proposition if the ai system and what outcomes are expected to be achieved through the use of the ai system table e.7', 'e.2.2.3 ai system functionalities and capabilities includes detailed description of the ai system features and capabilities and whether these are planned or current table e.5', 'identification of the intended use description of the intended use of the ai system as described in 6.3.4 identification of the intended use description of the intended use of the ai system as described in 6.3.4 e.2.2.6 unintended uses includes descriptions of reasonably foreseeable misuses table e.9']"
3,20,3_completed_organization__,"['completed', 'organization', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['5.4.5', '5.4.4', '5.1 n/a to be completed by the organization']"
4,19,4_thresholds_priorities_holistically_assessment,"['thresholds', 'priorities', 'holistically', 'assessment', 'assessments', 'approvals', 'organization', 'elevates', 'facilitate', 'varied']","['depending on the types and amounts of thresholds the organization can implement additional processes including reviews and approvals', 'however these individual assessments can be taken together holistically as the necessary inputs for iso/ iec 42001:2023 8.4', 'however these individual assessments can be taken together holistically as the necessary inputs for iso/ iec 42001:2023 6.1.4']"
5,19,5_explainability_parties_analyse_demographic,"['explainability', 'parties', 'analyse', 'demographic', 'transparency', 'benefits', 'oversight', 'unfairness', 'design', 'allocation']","['for each identified relevant interested party the organization should analyse the reasonably foreseeable benefits and harms related to transparency when the ai system is used', 'for each identified relevant interested party the organization should analyse the reasonably foreseeable benefits and harms related to explainability when the ai system is used', ""prior to models even being trained leading to better outcomes for relevant interested parties human oversight and control lack of human oversight and control can lead to issues and threats being prolonged proper human oversight and control allows issues to be caught early and remediated human oversight and control can lead to new insights and ai system improvements that benefit relevant interested parties transparency and explainability ai system explaina- bility relevant interested parties misinterpret or misunderstand intended purpose or use of ai system based on outputs relevant interested parties can not rely on ai system to support informed decision making overreliance on automation bias appropriate level of explainability can help to build trust and understanding among relevant interested parties explainability features can help backtracking errors in the ai system decision-making process communication to relevant interested parties relevant interested parties are not aware of ai system limitations parameters and settings that can enable responsible use critical safety information is not easily accessible or understandable relevant interested parties can be informed about the ai system 's intended use capabilities and limitations reducing the risk of misunderstandings or misuse the ai system can be used safely by relevant interested parties or safety obligations can be met in the case of suppliers and third parties objectives example harms example benefits disclosure of ai in- teraction relevant interested parties can interact with an ai system under the assumption it is human relevant interested parties can make informed decisions and consent to interacting with an ai system rather than human including divulging sensitive information fairness quality of service the quality of service is inconsistent across demographic groups leading to inequalities better performance for some groups over others quality of service is consistent across demographics bringing new opportunities to historically underprivileged groups allocation of oppor- tunity ai system outputs lead to the uneven allocation of opportunities to different demographic groups ai system outputs identify and mitigate uneven allocation of opportunities to different demographic groups minimization of ste- reotyping ai system outputs lead to stereotyping erasing or demeaning demographic groups ai system outputs help to identify trends in stereotyping erasing or demeaning demographic groups leading to solutions reliability failures and remedi- ations failures both predictable or unknown have no remediation plans and ai system providing critical services is unable to function well-planned system with reliable backup failure and remediation plans can lead to improved system reliability monitoring feed- back evaluation lack of monitoring renders datasets obsolete and ai system outputs become unreliable evaluation of systems finds errors before application security and privacy privacy protection and compliance with legal obligations and policies data used to train models is not appropriately protected for privacy and pii is used in systems that should not utilize it ai systems are trained on appropriately de-identified pii ensuring that system can provide benefits that are gleaned from personal data e.g""]"
6,18,6_23894_guidance_bank_application,"['23894', 'guidance', 'bank', 'application', '24027', 'grant', 'mobile', 'branch', 'notated', 'note']","['refer to iso/iec 23894:2023 a.10 for further information on the objective of safety', 'refer to iso/iec 23894:2023 a.6 for further information on the objective of fairness', 'refer to iso/iec 23894:2023 a.2 for further information on the objective of accountability']"
7,17,7_failures_impacts_misuse_performance,"['failures', 'impacts', 'misuse', 'performance', 'requirements', 'examples', 'consideration', 'threat', 'caused', 'algorithms']","['the following are examples of impacts to the relevant interested party for consideration whether the ai system does not meet stated performance requirements during its operation stage impacts in the event an update to the ai system data drift or concept drift see iso/iec 22989:2022 5.11.9.1 causes its performance to fail to meet requirements impacts arising from predictable failures such as false positives or false negatives whether the ai system or its outputs are compromised by unauthorized parties resulting in failure to meet stated performance requirements', 'the following are examples for consideration impacts to the relevant interested party including the following considerations the potential for the use of the ai system to result in an impact to their legal position life opportunities or human rights the potential of the use of the ai system to cause physical or psychological harm to the interested party impacts to the relevant interested party in the event that the ai system does not adequately fulfil the purpose it was deployed for impacts to the relevant interested party as result of selection and use of data used to develop the ai system impacts to the relevant interested party as result of not applying appropriate human oversight to the ai system and its outputs impacts to the relevant interested party as result of not being able to address or challenge decisions made by an ai system', 'table e.19 impacts of ai system failures failure description impacts resulting from potential failure include if it is benefit or harm description of potential failures that can have an impact on relevant interested parties description of impacts caused by identified potential failures description of potential failures that can have an impact on relevant interested parties description of impacts caused by identified potential failures e.2.8.2 impact of reasonably foreseeable misuse of ai system for each of the interested parties identified in in e.2.6 includes information on the impact of reasonably foreseeable misuse of the ai system under assessment table e.20']"
8,16,8_guide_alignment_rel_mapping,"['guide', 'alignment', 'rel', 'mapping', 'assessments', 'visual', 'docu', 'organizations', 'coordination', 'repetition']","['d.3 impact assessment alignment guide guide to help an organization to identify how existing impact assessments map to an ai system impact assessment and can be uplifted to expedite the process of completing an ai system impact assessment', 'table d.1 example visual guide for an impact assessment alignment guide row subclauses of this docu- ment numbered paragraphs of this docu- ment potential inputs from relevant hria potential inputs from rel- evant pia potential inputs from rel- evant eia potential inputs from rel- evant fia potential inputs from rel- evant bia potential inputs from rel- evant sia', '5.8 n/a key inputs likely to pertain to the ai system impact assessment d.4 mapping guide mapping guide is visual guide supported with explanatory material to demonstrate how an ai system impact assessment can be used in conjunction with other existing or related assessments to avoid repetition and duplication and comprehensively tackle and identify sources of risk of ai systems']"
9,16,9_privacy_rights_ethics_pii,"['privacy', 'rights', 'ethics', 'pii', 'procurement', 'cybersecurity', 'security', 'assessments', 'discrimination', 'registry']","['contemplating risk legal security privacy data ethics human rights procurement and architecture', 'risk legal security privacy data ethics human rights procurement or architecture', 'model training impacts resulting from privacy breach related to the processing of pii performed for the development or use of the ai system the obligations of the organization towards and the expectation from the relevant interested party related to pii processing and the mechanisms to fulfil the following obligations and expectation including but not limited to fairness risk of unwanted bias discrimination or accuracy risk of profiling and behavioural surveillance automated decision making and human intervention obtaining information means to exercise their rights']"
10,15,10_impact_duplication_assessment_coordination,"['impact', 'duplication', 'assessment', 'coordination', 'efficiently', 'organizational', 'multiple', 'components', 'trustworthy', 'interconnected']","['adding an impact assessment specific to ai systems without regard to how this can usefully draw on and contribute to other assessments that can be required can result in unnecessary friction cost and delay to the responsible use of ai systems', 'when the constituent components of an ai system have been identified an organization can better identify the range of impact assessments relevant to the ai system impact assessment enabling improved coordination across these assessments', 'one approach that an organization can use to expedite impact assessments and avoid duplication across processes is to deploy coordination guide that helps to align the relevant reviews required by an ai system impact assessment e.g']"
11,13,11_risk_management_organizational_impacts,"['risk', 'management', 'organizational', 'impacts', 'objectives', 'obligations', 'leadership', 'appetite', 'engagement', 'strategy']","['an organization performing risk management activities can understand reasonably foreseeable impacts to individuals and societies to appropriately incorporate into their overall organizational risk assessment', 'this clause can be viewed at management system level and describes the need for looking at system impact assessments holistically and as it relates to organizational risk', 'this clause can be viewed at management system level and describes the need for looking at ai system impact assessments holistically and as it relates to organizational risk']"
12,13,12_clause_documentation_needs_normative,"['clause', 'documentation', 'needs', 'normative', 'harmonized', 'documents', 'topics', 'commonality', 'structure', 'indicate']","['this is intended to support and mirror the management system standard approach where harmonized structure ensures commonality while allowing for variations', 'the organization should determine its needs based on its context and not all of the guidance in this clause is applicable to every organization', 'clause describes processes to be im- plemented by an organization while clause provides details on documentation']"
13,12,13_management_assessments_scale_consultation,"['management', 'assessments', 'scale', 'consultation', 'risks', 'compliance', 'governance', 'objectives', 'impacts', 'robust']","['on management level analysis can be used to inform the organizational risk management processes on foreseeable impacts of ai systems', 'this can include considerations such as how the organization integrates the ai system impact assessment with organizational risk assessment how the organization integrates the ai system impact assessment with other types of impact assessments which organizational governance risk and compliance processes are in place or planned for the treatment of reasonably foreseeable impacts', 'ai system impact assessment as opposed to general risk management addresses reasonably foreseeable impacts of ai systems to restricted set of relevant interested parties namely individuals groups of individuals societies and environment to potential or concrete uses of ai systems as opposed to overall governance and management issues such as business strategies compliance management financial management or technology strategies']"
14,12,14_dataset_data_synthetic_geographies,"['dataset', 'data', 'synthetic', 'geographies', 'provenance', 'datasets', 'risks', 'bias', 'storage', 'originators']","['information on data provenance known or reasonably foreseeable risks of unwanted bias in the dataset and geographies covered', 'data originators data holders data users processes applied to the data or data storage locations known or reasonably foreseeable risks of unwanted bias in the dataset geographies covered by the dataset processes for data quality access controls and protection of the dataset data temporal scope i.e', 'table e.10 data information dataset name version size identification of the dataset and additional information as needed dataset owner owner of the dataset where applicable dataset access rights information related to access control description of the contents of the dataset can include information on the data temporal scope and whether the datasets are real synthetic and semi-synthetic geographies covered by the dataset etc']"
15,12,15_algorithms_algorithm_models_documentation,"['algorithms', 'algorithm', 'models', 'documentation', 'development', 'requirements', 'scientific', 'repositories', 'journals', 'credible']","['6.5.2 information on algorithms used by the organization when developing documentation for the algorithms used in an ai system the organization should consider the following the appropriateness of the selected algorithms relative to business objectives and the ai task itself the origin of the algorithms and any modifications e.g', '6.5.5 information on model development when developing the documentation of models in an ai system impact assessment the organization should consider the following applicable legal organizational or technical requirements are met plans for achieving requirements that are not yet met documentation of models throughout the ai system development life cycle', '6.5.3 information on algorithm development when developing the documentation of algorithms in an ai system impact assessment the organization should consider the following applicable legal organizational or technical requirements are met plans for achieving requirements that are not yet met documentation of algorithms throughout the ai system development life cycle approval process for the algorithm used in the ai system']"
16,12,16_scope_internal_changes_impacts,"['scope', 'internal', 'changes', 'impacts', 'assessments', 'factors', 'contractual', 'applications', 'technology', 'policies']","['6.8.2.9 environmental impact the ai system impact assessment should consider the environmental impacts of an ai system including but not limited to both negative and positive impacts impacts emerging throughout the ai system life cycle from inception to retirement resource consumption the beneficial impacts resulting from the deployment of beneficial ai applications such as protecting endangered animal species or optimizing the performance of electrical smart grids the harmful impacts such as promoting and nudging environmentally unsustainable consumer behaviour', '5.5 scope of the ai system impact assessment the organization should define the scope of the ai system impact assessment including the applicability and the boundaries of the ai system impact assessments considering the internal and external factors provided in 5.1 the expectations of relevant interested parties and the reasonably foreseeable impacts on individuals groups of individuals or societies', 'determining the timing of the ai system impact assessments can be impacted by factors such as but not limited to applicable legal requirements contractual and professional obligations and duties internal structures policies processes procedures and resources including technology risk level of the ai system the organization can consider iso/iec 23894:2023 6.3.4 for additional guidance expectations of relevant interested parties including customers internal ai system life cycle processes for additional guidance on the timing of ai system impact assessments and how they can be connected or aligned with other impact assessments conducted by the organisation see annex d. 5.4.2 the organization should consider reassessment when changes arise in factors such as but not limited to change in intended use of the ai system including changes to the users of the ai system change in customer expectations change in the ai system itself including changes to the data used the complexity or type of the ai system the performance of the ai system changes in the operational environment of the ai system change in context surrounding the ai system including changes to the applicable legal requirements contractual obligations internal policies the relevant interested parties of the ai system the locations and sectors in which the organization operates or anticipates operating']"
17,11,17_clause_guidance_implementation_documentation,"['clause', 'guidance', 'implementation', 'documentation', 'guid', 'ance', 'assessment', 'creating', 'specifies', 'umenting']","['clause in this document pro- vides guidance on how to estab- lish and implement ai system impact assessment processes providing detailed guidance on how the organization can fulfil this control', '5.5 this clause describes addition- al factors to consider when defining roles and responsi- bilities for ai system impact assessment b.4.2 resource documentation implementation guidance the implementation guid- ance lists the following resources 6.6 clause 6.6 in this document addresses various aspects mentioned in b.4.2 as doc- umenting these elements are critical to being able to assess the impacts of the ai system', 'b.2.2 ai policy implementation guidance the implementation guid- ance states that the need to perform an ai system impact assessment should be docu- mented in the ai policy']"
18,10,18_individuals_societies_parties_impact,"['individuals', 'societies', 'parties', 'impact', 'represents', 'religion', 'gender', 'accessibility', 'digital', 'discriminate']","['6.7.2 directly affected interested parties the organization should identify and document individuals groups of individuals or societies that can be affected by an ai system and its intended use in the ai system impact assessment', 'description on how the ai system can affect the identified interested party individuals groups of individuals vulnerable groups societies data subjects etc', 'age range gender or religion the ai system represents the interested party in ways that unfairly discriminate against them based on their associated groups of population accessibility aspects for the relevant interested party so they are not excluded due to disabilities or lack of digital skills the impact of unwanted biases on at-risk groups']"
19,10,19_models_training_steps_retraining,"['models', 'training', 'steps', 'retraining', 'requirement', 'validation', 'testing', 'develop', 'evaluations', 'datasets']","['accuracy receiver operating characteristic confusion matrix root mean squared error or average distance to cluster centre evaluation of whether the selected models generalize well on production data description of evaluations to determine if models generalize to production data evaluation of whether the selected models per- petuate or create unwanted bias or other harms description of evaluations to determine if models perpetuate or create unwanted bias or other harms evaluation of whether output data from the model contains or creates pii description of evaluations to determine if models contain or create pii robustness of the model description of measures taken to evaluate the robustness of the models detection and correction of data drift e.g', 'training validation testing and the algorithms used to develop the models see 6.5.3 description of data and algorithms used to develop the model model training parameters and methods description of parameters and methods for model training data samples are not reused between training test and validation datasets description of steps taken to ensure that training validation and testing datasets are disjoint steps taken to train test and validate multiple models description of steps taken to develop multiple models criteria and steps taken to select appropriate features description of criteria defined and steps taken for feature selection criteria for model selection description of criteria defined for model selection metrics used to evaluate performance of the models e.g', 'training validation testing and the algorithms used to develop the models see 6.5.3 model training methods data samples are not reused between training validation and testing datasets steps taken to train test and validate multiple models criteria and steps taken to select appropriate features criteria for model selection metrics used to evaluate performance of the models e.g']"
20,10,20_quality_data_characteristics_5259,"['quality', 'data', 'characteristics', '5259', 'fulfilled', 'processes', 'description', 'datasets', 'presence', 'documentation']","['6.4.3 data quality documentation when documenting data quality in an ai system impact assessment the organization should consider the following which data quality characteristics apply to the context data quality requirements that are met plans for achieving data quality requirements that are not yet met use of data quality life cycle within the ai system development approved use of dataset in the ai system by appropriate interested parties', 'data quality characteristic significance to system planned date to be fulfilled name and description of the data quality characteristic information on data quality as described in 6.4.3 name and description of the data quality characteristic information on data quality as described in 6.4.3 e.2.4 algorithms and models information e.2.4.1 information on algorithms includes information about each algorithm that is developed for or used in the ai system table e.12', 'table e.11 data quality information data quality characteristics that are met data quality characteristic significance to the ai system date fulfilled relevant approvals name and description of the data quality characteristic information on data quality as described in 6.4.3 name and description of the data quality characteristic information on data quality as described in 6.4.3 data quality characteristics that are planned but not yet met']"
21,10,21_parties_behaviour_affect_role,"['parties', 'behaviour', 'affect', 'role', 'implications', 'unaware', 'targeted', 'perceive', 'stakeholder', 'misuse']","['description on how the ai system can affect the identified interested party table e.17 internal relevant interested parties internal relevant interested party name or team name role relative to the ai system e.g', '3.5 interested party stakeholder person or organization that can affect be affected by or perceive itself to be affected by decision or activity source iso/iec 42001:2023 3.2 3.6 reasonably foreseeable misuse use of an ai system in way not intended by the ai system developer or provider but which can result from readily predictable behaviour of intended users note to entry readily predictable human behaviour includes the behaviour of all types of users e.g', 'description on the role relative to the ai system and how potentially affected by it e.2.7 actual and reasonably foreseeable benefits and harms for each identified interested party identified in e.2.6 determines the actual and reasonably foreseeable benefits and harms to that party using the perspectives described in 6.8.2 table e.18']"
22,9,22_process_approvals_retention_documentation,"['process', 'approvals', 'retention', 'documentation', 'impact', 'reports', 'threshold', 'artefacts', 'assessment', 'requires']","['5.11 approval process the organization should document any approvals required as part of the ai system impact assessment process', 'when threshold is exceeded after the ai system impact assessment is completed who has the responsibility for approval this can vary depending on the type of approval whether external approvals are required in any situations e.g', 'the intended results of the process documentation can vary depending on the organization needs and the type of the ai system and can include for example documented procedural guidance ai system impact alignment guide or template refer to annex or standalone template see annex use cases for awareness-raising and training input in various management reviews in the related ai management system completed ai system impact assessments and other artefacts from the assessment process']"
23,9,23_geographic_environment_geographical_languages,"['geographic', 'environment', 'geographical', 'languages', 'cultural', 'traits', 'discriminated', 'physiological', 'region', 'locale']","['6.6.2 deployment environment complexity and constraints along with the geographical environment of the deployment the ai system impact assessment documentation should include information on the technical deployment environment and relevant constraints', 'when documenting the impact of an ai system deployed in particular country or region the organization should consider where the ai system is currently deployed and where it can be deployed in the future legal requirements specific to the geographic deployment area cultural considerations of the geographic deployment area discriminated groups at-risk groups and marginalized groups languages spoken in the geographic deployment area and particularly for natural language processing systems which languages that are currently supported behavioural social and physiological human traits that can be present in geography', 'table e.14 deployment environment a1 where the ai system is currently deployed indication of geographical areas where the system is currently deployed a2 planned deployment locations indication of geographical areas where the system is planned to be deployed in the future legal requirements specific to the geographic deployment area list of legal requirements relevant for the geographic deploy- ment area cultural considerations of the geographic deployment area description of relevant cultural specifics of the geographic deployment area discriminated groups at-risk groups and marginalized groups description of discriminated at-risk or marginalized groups of the geographic deployment area as relevant to the ai system under assessment languages spoken in the geographic deploy- ment area description of language spoken in the geographic deployment area as relevant to the ai system under assessment particularly for natural language processing systems behavioural social and physiological human traits that can be present in geography description of behavioural social or physiological traits as aspects relevant to the ai system under assessment e.2.5.2 deployment environment complexity and constraints includes information on the technical deployment environment of the ai system table e.15']"
24,8,24_pact_guidance_assessment_implementation,"['pact', 'guidance', 'assessment', 'implementation', 'ument', 'roles', 'informative', 'guid', 'impact', 'annexes']","['b.6.1.3 processes for responsible de- sign and develop- ment of ai systems implantation guid- ance the control addresses the implementation and docu- mentation of processes on ai system impact assessment both clauses of this document discuss integration of the im- pact assessment into the over- all ai life cycle table a.1 continued table a.1 continued annex informative guidance for use with iso/iec b.1 general iso/iec provides guidance on risk management for organizations developing providing or using ai systems', 'iso/iec 42001:2023 type summary this document guidance on how this doc- ument supports iso/iec 42001:2023 b.3.2 roles and re- sponsibilities implementation guidance the implementation guid- ance states that the organ- ization should take the ai system impact assessment into account when assigning roles and responsibilities', 'table a.1 clauses in iso/iec relevant for this document iso/iec 42001:2023 type summary this document guidance on how this doc- ument supports iso/iec 42001:2023 6.1.4 ai system im- pact assessment requirement iso/iec 42001:2023 6.1.4 addresses ai system impact assessment in general by stipulating the need for the organization to establish an impact assessment process to determine the impact an ai system can have on in- dividuals and societies']"
25,8,25_framework_terminology_modified_terms,"['framework', 'terminology', 'modified', 'terms', 'maintain', 'standardization', 'sustainability', 'databases', 'supplier', 'electropedia']","['source iso/iec guide 51:2014 3.7 modified product or system has been replaced with an ai system and supplier has been replaced with ai system developer or provider', 'iso/iec information technology artificial intelligence artificial intelligence concepts and terminology iso/iec framework for artificial intelligence ai systems using machine learning ml terms and definitions for the purposes of this document the terms and definitions given in iso/iec iso/iec and the following apply', 'iso and iec maintain terminology databases for use in standardization at the following addresses iso online browsing platform available at iec electropedia available at 3.1 ai system impact assessment formal documented process by which the impacts to individuals groups of individuals and societies are considered by an organization developing providing or using products or services utilizing artificial intelligence 3.2 intended use use for which an ai system is designed 3.3 unintended use use for which an ai system is not designed 3.4 intended users groups of people or information systems for which an ai system is designed source iso 20282-1:2006 3.12 modified people has been replaced with people or information systems and product has been replaced with an ai system']"
