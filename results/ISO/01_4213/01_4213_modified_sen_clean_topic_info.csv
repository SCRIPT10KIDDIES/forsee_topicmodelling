Topic,Count,Name,Representation,Representative_Docs
-1,65,-1_momentum_decay_divergence_kullback,"['momentum', 'decay', 'divergence', 'kullback', 'leibler', 'rate', 'mortality', 'batch', 'models', 'distributions']","['the precision and recall weight can also be directly applied with the pair value of through the following 6.2.7 kullback-leibler divergence kullback-leibler divergence dkl is well-known measure for quantifying the difference between target distribution and an estimated distribution', '3.2.18 majority class class with the most samples in dataset abbreviated terms ai artificial intelligence anova analysis of variance auprc area under the precision recall curve auroc area under the receiver operating characteristic curve clt central limit theorem cpu central processing unit crc cumulative response curve fc fully connected fdr false discovery rate iou intersection over union gpu graphics processing unit roc receiver operating characteristic general principles 5.1 generalized process for machine learning classification performance assessment generalized process for machine learning classification performance assessment is shown in figure', 'table c.1 summary information from machine learning classification benchmark tests dataset model accuracy top-1 error top-5 error model depth parameters model parameters and values imagenet alexnet 63,3 37,5 17,0 conv fc 60m batch size momentum 0,9 weight decay 0,0005 learning rate 0,01 vgg-19 74,5 25,5 conv fc 144m batch size momentum 0,9 weight decay 0,000 learning rate 0,01 resnet-50 77,15 22,85 6,7 conv fc 20m batch size momentum 0,9 weight decay 0,0001 learning rate 0,1 efficient- net-b7 84,4 15,6 2,9 66m momentum 0,9 weight decay 0,0001 learning rate 0,256 mnist rmdl 99,82 mcdnn 99,77 conv pooling fc lenet 99,3 conv pooling fc dataset model accuracy top-1 error top-5 error model depth parameters model parameters and values cifar-10 efficient- net-b7 98,9 64m momentum 0,9 weight decay 0,0001 learning rate 0,256 colornet 98,46 19,0m momentum 0,9 decay rate 0,95 learning rate 0,0001- 0,001 densenet 96,54 batch size momentum 0,9 weight decay 0,0001 learning rate 0,1 dropout rate 0,2 lfw facenet 99,63 7,5m learning rate 0,05 deepid3 99,53 deepface 97,5 batch size learning rate 0,01 table c.1 continued table c.1 continued \ufeff\x08 annex informative chance-corrected cause-specific mortality fraction d.1 calculating chance-corrected cause-specific mortality fraction accuracy the cause-specific mortality fraction csmf is the fraction of in-hospital deaths for given cause normalized over all causes where the underlying cause of death has been coded according to the international classification of diseases']"
0,24,0_classes_samples_target_outlier,"['classes', 'samples', 'target', 'outlier', 'binary', 'classification', 'classified', 'negative', 'labelled', 'seizure']","['6.4 multi-class classification 6.4.1 general in multi-class classification each sample is labelled as one of three or more mutually exclusive classes', 'let fpi denote the number of samples from other classes incorrectly classified as class', 'let denote the total number of samples in all classes']"
1,22,1_multi_hamming_loss_label,"['multi', 'hamming', 'loss', 'label', 'ratio', 'classification', 'performance', 'jaccard', 'index', 'metric']","['total hamming loss can be expressed as follows ∑∑ 6.5.3 exact match ratio exact match ratio or subset accuracy is the percentage of samples for which all labels are predicted and predicted accurately', 'different metrics are available to assess multi-label machine learning classification performance including hamming loss exact match ratio and the jaccard index', '6.5.5 distribution difference or distance metrics similar to the distribution difference method to assess multi-class machine learning classification performance multi-label machine learning classification evaluation considers the difference in class distributions between labelled data and predicted data using the following let ti be the number of samples for each class']"
2,22,2_machine_performance_classification_assessment,"['machine', 'performance', 'classification', 'assessment', 'baseline', 'approaches', 'relevance', 'assertions', 'ranks', 'tasks']","['machine learning model classification performance can be represented through the following examples new model achieves 97,8 classification accuracy on dataset where the state-of-the-art model achieves just 96,2 accuracy', '5.3 control criteria in machine learning classification performance assessment 5.3.1 general when assessing machine learning classification performance consistent approaches and methods should be applied to demonstrate relevance legitimacy and extensibility', '5.3.14 machine learning classification performance context it is important to consider the overall system including components and sub-systems in which machine learning model will be deployed when assessing machine learning model performance']"
3,21,3_latency_throughput_classification_ncla,"['latency', 'throughput', 'classification', 'ncla', 'complexity', 'pipeline', 'latencies', 'inefficient', 'machine', 'computational']","['in addition to these metrics aspects of classification performance such as computational complexity latency throughput and efficiency can be relevant', 'classification throughput can be expressed as follows cla where ncla is the total number of samples for which machine learning model generates an inference in given period of time under latency constraints te is the time at which inference ends for the ncla samples tb is the time at which begins for the ncla samples', '\ufeff\x08 6.6.3 classification throughput classification throughput is the number of inferences per unit of time that machine learning model computes given latency constraints']"
4,21,4_null_hypotheses_bonferroni_fdr,"['null', 'hypotheses', 'bonferroni', 'fdr', 'references', 'topics', 'statistical', 'discovery', 'comparisons', 'significant']","['for example if statistical test is performed at the level and the corresponding null hypothesis is true there is only chance of incorrectly rejecting the null hypothesis', 'however if tests are performed and all corresponding null hypotheses are true the expected number of incorrect rejections is 0,05 n. if the tests are statistically independent from each other the probability of at least one incorrect rejection grows with the number of tests', '7.10.2 bonferroni correction the bonferroni correction is as follows let h1 hm be family of null hypotheses with p1 pm as their corresponding p- values']"
5,20,5_table_matrix_binary_false,"['table', 'matrix', 'binary', 'false', 'classification', 'f1', 'classified', 'precision', 'recall', 'csmf']","['table a.2 notional true positive true negative false positive and false negative counts for classes tp tn fp fn table a.3 shows binary accuracy precision recall specificity and f1 for each class calculated from the counts shown in table a.2', 'table a.1 confusion matrix for multi-class classification with classes actual predicted table a.2 shows notional true positive true negative false positive and false negative counts for each class', 'table elements of binary confusion matrix true classes positive negative predicted classes positive true positive tp false positive fp negative false negative fn true negative tn 6.3.3 accuracy for binary classification in the case of binary classification the application of the definition of accuracy leads to the following computation 6.3.4 precision recall specificity f1 score and fβ for binary classification in the case of binary classification the terms precision recall specificity f1 score and fβ refer to the computation of those metrics for the positive class']"
6,20,6_training_leakage_information_biases,"['training', 'leakage', 'information', 'biases', 'limiting', 'composition', 'source', 'misleading', 'instances', 'generalize']","['5.3.7 limiting information leakage information leakage occurs when machine learning algorithm uses information not in the training data to create machine learning model', 'extra care should be taken when splitting unbalanced data into training and test to ensure that similar distributions are maintained between training data validation data and test data', 'reporting the following should be reported source size and composition of training data source size and composition of test data efforts taken to analyse account for and reduce bias in test and training data methods by which ground truth is established in test and training data reliability of ground truth in test and training data and its potential impact on statistical significance number of true and false positive instances correctly and incorrectly classified at representative operating points test environment to include hardware cpu/gpu or other processing architecture and software operating system used to generate inferences with specific versions and generations inference generation duration or other measures of computational efficiency']"
7,19,7_curve_thresholds_tp_graphical,"['curve', 'thresholds', 'tp', 'graphical', 'roc', 'axis', 'lift', 'values', 'prc', 'percentage']","['the process is illustrated in figures b.1 to b.7 where shows an incorrect classification at this threshold and black circle shows correct classifications plotting actual class values against predicted probabilities of each sample figure b.1 threshold 0,99 vertical line where tp rate 0,18 and fp rate figure b.2 threshold 0,9 where tp rate 0,68 and fp rate 0,02 figure b.3 threshold 0,7 where tp rate 0,75 and fp rate 0,03 figure b.4 threshold 0,3 where tp rate 0,96 and fp rate 0,14 figure b.5 threshold 0,01 where tp rate and fp rate 0,59 figure b.6 roc curve rendered from performance at multiple operating points figure b.7', '\ufeff\x08 key predicted probability actual values figure b.1 plotting of actual class values against predicted probabilities of each sample key predicted probability actual values figure b.2 threshold 0,99 tp rate 0,18 fp rate key predicted probability actual values figure b.3 threshold 0,9 tp rate 0,68 fp rate 0,02 key predicted probability actual values figure b.4 threshold 0,7 tp rate 0,75 fp rate 0,03 \ufeff\x08 key predicted probability actual values figure b.5 threshold 0,3 tp rate 0,96 fp rate 0,14 key predicted probability actual values figure b.6 threshold 0,01 tp rate fp rate 0,59 the points are then joined to create the roc curve key false positive rate true positive rate threshold 0,99. threshold 0,9. threshold 0,7. threshold 0,3. threshold 0,01', '3.2.13 cumulative response curve gain chart graphical method of displaying true positive rates 3.2.10 and percentage of positive prediction in the total data across multiple thresholds 3.2.14 lift curve graphical method of displaying on the y-axis the ratio of true positive rate 3.2.10 between the model and random classifier and on the x-axis the percentage of positive predictions in the total data across multiple thresholds 3.2.15 precision recall curve prc graphical method for displaying recall 3.2.10 and precision 3.2.9 across multiple thresholds note to entry prc is more suitable than roc receiver operating characteristic curve for showing performance with imbalanced data']"
8,16,8_images_labels_resolution_text,"['images', 'labels', 'resolution', 'text', 'software', 'spam', 'categorize', 'features', 'classify', 'learning']","['however if all cat images are high-resolution and all dog images are low-resolution machine learning classifier can learn to classify images based on resolution as opposed to content', 'example multi-label machine learning classification software learns to categorize text as one or more of opinion news hostile sympathetic misinformation or disinformation based on labels assigned by human reviewer', 'example machine learning classification software learns to categorize images as dog cat or other based on labels assigned by human reviewer']"
9,16,9_f1_micro_weighted_macro,"['f1', 'micro', 'weighted', 'macro', 'majority', 'recall', 'imbalance', 'precision', 'classes', 'approaches']","['multi-class performance can be expressed using one or more of macro- average weighted-average and micro-average approaches', '6.4.3 macro-average weighted-average and micro-average several multi-class classification metrics are based on the averaging of per-class metrics precision recall specificity and f1 score', '\ufeff\x08 using f1 for illustration macro-average f1 weighted-average f1 and micro-average f1 approaches are as follows macro-average f1 averages f1 for each class without accounting for the number of samples within each class']"
10,16,10_hyperparameters_parameters_hyperparameter_optimize,"['hyperparameters', 'parameters', 'hyperparameter', 'optimize', 'loop', 'outer', 'models', 'training', 'validation', 'generative']","['for example generative algorithms can optimize parameters such that the probability of the available training data is maximized whereas discriminative algorithms can optimize parameters to maximize classification accuracy', 'machine learning algorithms use hyperparameters and training data to establish internal parameters', '5.3.10 machine learning algorithms hyperparameters and parameters most machine learning algorithms have characteristics that affect their learning processes known as hyperparameters']"
11,14,11_chi_contingency_mcnemar_wallis,"['chi', 'contingency', 'mcnemar', 'wallis', 'parametric', 'nominal', 'wilcoxon', 'frequencies', 'tables', 'ranks']","['7.5 chi-squared test the chi-squared test is method for determining for independent categorical variables whether observed and expected frequencies match', 'the chi-squared test uses contingency table to determine whether two variables are associated resulting in test statistic with chi-squared distribution', '7.9 mcnemar test the mcnemar test is non-parametric test applied to paired nominal data represented in contingency tables']"
12,13,12_energy_consumption_frames_joules,"['energy', 'consumption', 'frames', 'joules', 'performance', 'jpf', 'dt', 'analyse', 'classified', 'fpj']","['corresponding measure joules per frame jpf can be represented as follows dt pf where is the total number of frames inferred and is the total time required to analyse frames', 'similarly average power for given interval can be represented by e/t where is energy measured in joules', '6.6.5 energy consumption it is important to consider how performance and implementation of an ai system will be constrained by the energy consumption bounds such as performance per watt']"
13,13,13_precision_recall_samples_entry,"['precision', 'recall', 'samples', 'entry', 'detected', 'classified', 'positives', 'fβ', 'importance', 'rate']","['3.2.10 recall true positive rate sensitivity hit rate number of samples correctly classified as positive divided by all positive samples note to entry it is calculated as', '6.2.4 precision recall and specificity as precision increases more true positives are detected but false negatives are not accounted for', '3.2.9 precision positive predictive value number of samples correctly classified as positive divided by all samples classified as positive note to entry it is calculated as']"
14,13,14_cross_validation_fold_techniques,"['cross', 'validation', 'fold', 'techniques', 'train', 'performance', 'runs', 'rough', 'extrapolating', 'permutations']","['however cross-validation does not provide performance assessment of that final model and extrapolating performance from the output of cross-validation is rough approximation with no guarantee of faithfulness', 'it is also important if the evaluation methodology is based on approaches such as k-fold cross-validation that use multiple permutations of dataset to train and test model', '5.3.6 cross-validation cross-validation is method to estimate the performance of machine learning method using single dataset']"
15,11,15_evaluation_environment_processing_requirements,"['evaluation', 'environment', 'processing', 'requirements', 'step', 'application', 'implement', 'generate', 'hardware', 'software']","['when it is infeasible to implement the required minimum environmental requirements with the actual application an evaluation environment can be designed to simulate an actual application', '5.3.11 evaluation environment evaluation environmental requirements are as follows the evaluation environment shall not be modified while the assessment is in progress hardware and system software shall not be modified during the assessment the same test environment should be considered for the machine learning models under assessment', 'step conduct evaluation create the evaluation plan implement the evaluation environment including software and hardware prepare datasets and process datasets']"
16,10,16_approaches_23053_ml_framework,"['approaches', '23053', 'ml', 'framework', 'roles', 'language', 'developers', 'domains', 'stakeholder', 'terminology']","['for example ai developers can use the approaches and methods when evaluating ml models', 'various ai stakeholder roles as defined in iso/iec 22989:2022 5.17 can take advantage of the approaches and methods described in this document', 'iso/iec 22989:2022 information technology artificial intelligence artificial intelligence concepts and terminology iso/iec 23053:2022 framework for artificial intelligence ai systems using machine learning ml terms and definitions for the purposes of this document the terms and definitions in iso/iec 22989:2022 iso/iec 23053:2022 and the following apply']"
17,10,17_values_indicator_iou_input,"['values', 'indicator', 'iou', 'input', 'labelled', 'predictions', 'target', 'set', 'tp', 'data']","['li =1 if label is present among the ground truth labels for xi otherwise li =0', 'let li =ˆ li li li denote the predicted label values for xi', 'similarly let li li ,1 li,2 li denote the ground truth label values for xi']"
18,9,18_set_test_training_validation,"['set', 'test', 'training', 'validation', 'disjoint', 'permutation', 'segments', 'dataset', 'tuning', 'times']","['5.3.5 test and validation data the data used to test machine learning model shall be the same for all machine learning models being compared', 'the dataset is divided into segments where one segment is used for test while the rest is used for training', 'when label information is needed for such tuning it is typically drawn from separate set of data called the validation set which is disjoint from the test set']"
19,9,19_channel_data_controlling_turn,"['channel', 'data', 'controlling', 'turn', 'balance', 'contributes', 'training', 'effect', 'assessments', 'lead']","['the data should be as free of channel effects as possible', 'note one method of reducing channel effects is to balance channel distributions for each class in the data', '5.3.8 limiting channel effects channel effect is characteristic of data that reflects how data were collected as opposed to what data were collected']"
20,8,20_preprocessing_data_assessment_comparative,"['preprocessing', 'data', 'assessment', 'comparative', 'claims', 'inconsistent', 'outliers', 'resolving', 'filtering', 'biased']","['examples of preprocessing include removal of outliers resolving incomplete data or filtering out noise', '5.3.4 training data special care should be taken in the choice of training and validation data and how the choice impacts performance assessment especially in the case of comparative assessment', '5.3.3 preprocessing special care should be taken in preprocessing and its impact on performance assessment especially in the case of comparative assessment']"
21,8,21_auroc_suited_cases_auprc,"['auroc', 'suited', 'cases', 'auprc', 'crc', 'imbalanced', 'positives', 'ranked', 'classifiers', 'chance']","['auprc is well-suited for cases where achieving good results on the positive class is important as well as when data are imbalanced', 'auroc is well-suited for cases where ranked predictions are important', 'auroc is not well- suited for cases in which data are imbalanced because it does not account for the proportion of false positives and true positives']"
22,8,22_variance_anova_groups_squared,"['variance', 'anova', 'groups', 'squared', 'sum', 'statistic', 'means', 'analysis', 'centred', 'ratio']","['the sum of squares within-group is based on the squared sum of values centred on each group overall mean', 'the sum of squared differences between groups expresses group means deviance from the overall mean', 'anova is based on between-group and within-group mean-squared values']"
