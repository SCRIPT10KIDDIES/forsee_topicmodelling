Topic,Count,Name,Representation,Representative_Docs
-1,62,-1_factors_organization_confidence_hardware,"['factors', 'organization', 'confidence', 'hardware', 'risks', 'values', 'ethical', 'considerations', 'mitigation', 'backup']","['if fi the set of the significant life cycle factors .. =1 for specific ai system is the probability density function of', 'the description of the context of use can be formed as set of significant life cycle factors with specified estimates of the statistical characteristics probability density functions of each factor throughout the life cycle of an ai system', 'an ai system should generate representative outputs under abnormal environmental conditions by leveraging confidence score or confidence intervals to decide whether to act on the output generated or if backup workflow should be triggered calibrating confidence score or confidence intervals to be representative of the uncertainty relative to the output being true by using calibration measurements validated on testing data integrating backup workflow such as manual queue heuristics model statistical model or separate ai system to overwrite outcomes from an ai system that are considered abnormal or too uncertain based on their confidence scores or confidence intervals implementing robust backup workflow that should be operational when an ai system fails to generate outputs']"
0,24,0_ml_model_validation_testing,"['ml', 'model', 'validation', 'testing', 'deployment', 'datasets', 'phase', 'training', 'resource', 'process']","['the ml engineer can suggest new ml model deployment options', 'the organization should take into consideration resource trade-offs when selecting the best ml model for deployment as the most accurate ml model can be prohibitively expensive to computationally evaluate', 'in separate back-testing phase the selected ml model should be tested once again with new data the testing dataset for consistency']"
1,21,1_quality_software_evaluation_coverage,"['quality', 'software', 'evaluation', 'coverage', 'square', 'engineering', 'ieee', 'requirements', 'formula', 'definitions']","['iso and iec maintain terminology databases for use in standardization at the following addresses iso online browsing platform available at iec electropedia available at overview to ensure that relevant facets of an ai system quality are covered by the quality evaluation guidance this document references systems and software quality requirements and evaluation square product quality and quality in use models characteristics for an ai system see iso/iec', 'iso/iec ts information technology artificial intelligence assessment of machine learning classification performance iso/iec information technology artificial intelligence artificial intelligence concepts and terminology iso/iec 23053:2022 framework for artificial intelligence ai systems using machine learning ml iso/iec 25059:2023 software engineering systems and software quality requirements and evaluation square quality model for ai systems iso/iec/ieee 29119-1 software and systems engineering software testing part general concepts iso/iec/ieee systems and software engineering life cycle processes requirements engineering terms and definitions for the purposes of this document the terms and definitions given in iso/iec ts iso/iec iso/iec iso/iec iso/iec/ieee 29119-1 and iso/iec/ieee apply', 'vi technical specification systems and software engineering systems and software quality requirements and evaluation square guidance for quality evaluation of artificial intelligence ai systems scope this document provides guidance for evaluation of artificial intelligence ai systems using an ai system quality model']"
2,20,2_domain_weights_input_conceptual,"['domain', 'weights', 'input', 'conceptual', 'components', 'adjustments', 'target', 'training', 'knowledge', 'retraining']","['an ai system embeds knowledge in its learned weights but the meaning of those weights requires contextualization by both the input and output components', 'transfer learning for an ml-based ai system ml model weights within the system are carefully tuned on small set of data comprising the new conceptual domain to reuse weights already in the system to identify useful features', 'possible approaches for changing the target domain of an ai system include the following retraining for an ml-based ai system the system is retrained in its entirety using fresh training set inclusive of the new conceptual domain']"
3,17,3_interoperability_modifiability_installability_aesthetics,"['interoperability', 'modifiability', 'installability', 'aesthetics', 'testability', 'analysability', 'learnability', 'adaptability', 'maintainability', 'portability']","['portability 13.1 adaptability quality of the adaptability sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.9.1', '12.2 reusability quality of the reusability sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.8.2', '9.2 learnability quality of the learnability sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.5.2']"
4,16,4_adaptability_retraining_functional_strategy,"['adaptability', 'retraining', 'functional', 'strategy', 'learning', 'adaptation', 'adapted', 'resources', 'selects', 'incremental']","['consider as part of this adaptability strategy that inference and retraining can happen simultaneously', 'for example an adaptability strategy consisting of retraining an ai system hourly takes few resources during inference but several resources during the retraining', '6.4 functional adaptability an ai system should have mechanism to adapt dynamically to changes in the production data by using one of the following deploying continuous or reinforcement learning modelling approach implementing an automated retraining workflow']"
5,12,5_workflows_duration_functionality_operations,"['workflows', 'duration', 'functionality', 'operations', 'task', 'production', 'processes', 'retraining', 'organization', 'resources']","['number of operations needed by control functionality total number of operations controller should carry out such that the entire control functionality process can complete and return results', 'duration of control functionality length of time needed by sub-process or the entire process to complete control functionality', 'the organization should calculate time behaviour during the training evaluation and inference workflows under normal conditions as part of normal workflows in production using the production environment infrastructures and computing resources as time behaviour depends on resource utilization']"
6,12,6_testing_functionalities_controllability_robustness,"['testing', 'functionalities', 'controllability', 'robustness', 'adversarial', 'operational', 'functionality', 'metamorphic', 'instruction', 'augmentation']","['for an evaluation the following should be considered and prepared in advance ai system that is runnable and with control functionalities implemented according to requirements test items that are designed specifically for the test of control functionalities toolkits capable of issuing controllability instructions receiving or observing system appearance or internal parameter changes as well as computing concerned measures e.g', 'the following actions should be considered to measure the ai system robustness against the bounded domain assess training validation and testing dataset to ensure they cover normal operational conditions develop specific test scenarios to test the system performance under wide range of normal operational conditions use simulation as test data generator to address the full range of operation consider regularization techniques data augmentation or introduction of random noise to maximize robustness of an ai system under normal operating conditions evaluate functional correctness see 6.2 for the recommended guidance on functional correctness and iso/iec tr 24029-1:2021 5.2 for robustness metrics', 'functional correctness should also be evaluated using functional testing methods such as metamorphic testing technique that establishes relationships between inputs and outputs of the system expert panels technique used when an ai system is built to replace the judgement of experts which consists of establishing panel to review the test results benchmarking an ai system technique used when an ai system is replacing existing approaches or when similar ai system can be used as benchmark testing an ai system behaviours against various scenarios or test cases defined by stakeholders testing in simulated environment technique used when an ai system is characterized by physical action on the environment field trials technique used when there is potential difference or evolution between testing environments and actual operation conditions risk management testing ai system behaviour against identified risk scenarios']"
7,11,7_quality_measures_accountability_satisfaction,"['quality', 'measures', 'accountability', 'satisfaction', 'usefulness', 'effectiveness', 'utilization', 'appropriateness', 'behaviour', 'performance']","['functional suitability 6.1 functional completeness quality of the functional completeness sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.2.1', '18.2 context completeness quality of the context completeness sub-characteristic should be measured against quality measures according to iso/iec 25022:2016 8.6.2', 'efficiency quality of the efficiency sub-characteristic should be measured against quality measures according to iso/iec 25022:2016 8.3']"
8,11,8_quality_tolerance_availability_capacity,"['quality', 'tolerance', 'availability', 'capacity', 'authenticity', 'trust', 'integrity', '61508', 'security', 'failures']","['11.5 authenticity quality of the authenticity sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.7.5', '11.2 integrity quality of the integrity sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.7.2', 'security 11.1 confidentiality quality of the confidentiality sub-characteristic should be measured against quality measures according to iso/iec 25023:2016 8.7.1']"
9,10,9_learnability_repetition_improve_curve,"['learnability', 'repetition', 'improve', 'curve', 'technical', 'commands', 'peers', 'productivity', 'lessons', 'learnt']","['an evaluation of learnability measures can be made and can include the following user testing users can rate the degree to which they can learn how to use an ai system', 'for example users with technical background or general ai understanding can learn how to perform task and use commands in shorter times while users with non-technical background need good user interface to reach the learnability goals', 'other learnability evaluation tools the learning curve which is the relationship between time and task repetition provides information on first-use learnability how quickly users improve with repetition steepness of the curve how the productivity of the user can improve if they learn how to use the system appropriately efficiency of the ultimate plateau']"
10,9,10_outcomes_stakeholders_outputs_organization,"['outcomes', 'stakeholders', 'outputs', 'organization', 'development', 'interpretability', 'logging', 'code', 'accountable', 'guidelines']","['the relevant characteristics used in an ai system should be comprehensive accessible clear and understandable to the stakeholders', 'an ai system should have clear owners who are accountable for meeting the expected benefits and communicating about the system outcomes to the stakeholders', 'one significant pitfall of an ai system is its weak explainability and interpretability capabilities as the outcomes of an ai system are generated from its training data and are not as explicit as in software development in which the code is producing the outcomes']"
11,9,11_transparency_references_undated_documents,"['transparency', 'references', 'undated', 'documents', 'amendments', 'constitutes', 'presentation', 'guidelines', 'utilization', 'comprehensive']","['for dated references only the edition cited applies', '16.6 transparency refer to 9.8 for the recommended guidance on transparency', 'for undated references the latest edition of the referenced document including any amendments applies']"
12,9,12_safety_health_requirements_assumptions,"['safety', 'health', 'requirements', 'assumptions', 'risk', 'design', 'hazards', 'constraints', 'component', 'management']","['which risks to treat focus on risk identification and reduction rather than on hazard identification and removal focus or identification of user or operator error claims or statements that the ai system is or components of the system are safe note for the purpose of this document safety is considered to be an emergent property of socio-technical system with human procedural and technical components that arises from the interaction of its component parts', 'to effectively mitigate safety risks an organization should identify health and safety requirements of their systems according to intended use apply health and safety risk mitigation methods at the system level identify software quality requirements derived from and traceable to the system level health and safety ai system requirements identify and address health and safety risks relating to human procedural and technical elements of their systems implement and operate an effective organizational safety management system covering the entire life cycle of the ai system integrate its software management system into the organization ai quality management system see iso/iec state commitment to improving health and safety risk mitigation ensure that the domain and requirements engineering activities have been undertaken by sufficiently interdisciplinary team of experts identify the environment in which their systems are intended to be used the goals of its ai system safety constraints behavioural boundaries within which its ai systems can operate safely implement control measures to ensure that health and safety constraints are not violated implement measures for the identification and prevention of unwanted losses the elimination removal and reduction of hazards including through system design programming language and development method selection learn continuously about health and safety risk mitigation identify and respond to both leading and lagging health and safety indicators undertake rigorous quality evaluation of the ai system requirements analysis to ensure that it includes the identification of health and safety goals the identification of safety constraints the identification of component interaction failure modes this includes individual component failure modes in the form of social procedural and technical forms undertake human factors engineering in systems requirements analysis and in system design and operation list detailed assumptions about the specified intended domain and intended operational use of the ai system note an organization can include divergence of listed assumptions from the domains and use in which it plans to use ai systems as source of risk to be addressed and as system selection factor', 'an organization should prevent the following situations absence of meaningful oversight over the selection design development operation maintenance or decommissioning of the ai system iso/iec absence of specific safety goals and requirements safety requirements developed after the ai system has been designed documented assumptions that do not hold true for the intended use of the ai system absence of documented assumptions conflation of other quality characteristics with that of safety for example redundancy robustness useability note as indicated in the introduction to this clause these and other quality characteristics can have significant bearing on the health and safety relating to an ai system but they do not in themselves constitute safety']"
13,9,13_environmental_consumption_impacts_negative,"['environmental', 'consumption', 'impacts', 'negative', 'mining', 'optimizes', 'development', 'risks', 'predicts', 'waste']","['the impacts of the ai application as the application of ai and its structural and behavioural effects can cause both positive and negative indirect environmental impacts', 'an organization should identify potential direct and indirect harms and benefits related to an ai system regarding environmental considerations such as energy consumption greenhouse gas emissions or water consumption as described in reference', 'for example an ai system that optimizes mining operations can exacerbate the negative environmental impacts of the mining extractive and manufacturing sectors or an ai system that generates product recommendations used in e-commerce can increase consumption in unsustainable ways']"
14,8,14_ts_measurements_thresholds_publication,"['ts', 'measurements', 'thresholds', 'publication', 'specifications', 'dts', 'operating', '23053', 'estimates', 'additional']","['this document does not state exact measurements and thresholds as these vary depending on the nature of each system', 'source iso/iec 25059:2023 figure', 'source iso/iec 25059:2023 figure']"
15,8,15_mitigation_safety_environmental_25022,"['mitigation', 'safety', 'environmental', '25022', 'risks', 'requirements', 'balancing', 'standards', 'security', 'maintenance']","['17.2 economic risk mitigation quality of the economic risk mitigation sub-characteristic should be measured against quality measures according to iso/iec 25022:2016 8.5.2', '17.3 health and safety risk mitigation the organization should measure the quality of the health and safety risk mitigation sub-characteristic against quality measures according to iso/iec 25022:2016 8.5.3', '17.4 environmental risk mitigation quality of the environmental risk mitigation sub-characteristic should be measured against quality measures according to iso/iec 25022:2016 8.5.4']"
