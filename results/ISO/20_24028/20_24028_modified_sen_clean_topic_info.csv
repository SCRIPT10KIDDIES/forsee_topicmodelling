Topic,Count,Name,Representation,Representative_Docs
-1,104,-1_control_mitigation_vulnerabilities_risk,"['control', 'mitigation', 'vulnerabilities', 'risk', 'training', 'objectives', 'tree', 'threats', 'data', 'trustworthiness']","['square series distinguish between the following models quality of software product resulting in list of characteristics quality in use of software product data and it services resulting in list of characteristics giving way to differentiate cyber trust and social trust specifying also possible risks to mitigate data quality resulting in list of characteristics and it service quality resulting in list of characteristics', 'control objectives typically correspond to vulnerabilities pitfalls or anticipated threats.1 for ai systems these would include but not be limited to challenges to accountability new security threats new privacy threats improper specification deficient implementation incorrect use and different sources of bias', '9.4.2 human-in-the-loop control points regarding the role of humans within the lifecycle of ai systems two roles are particularly relevant as human-in-the-loop control points decision makers having agency and autonomy in the final decision-making process to factor into account the outcomes of ai systems where they are used to augment human decision-making domain experts given the opportunity to provide feedback to not only re-assess the level of trust of the system but also to improve the operation of the system']"
0,37,0_faults_hardware_errors_fault,"['faults', 'hardware', 'errors', 'fault', 'redundancy', 'faulty', 'failures', 'intermittent', 'runtime', 'bugs']","['9.8 mitigating system hardware faults robust and fault tolerant systems are achieved by different methods that are related to the architecture and detailed design of the hardware but also the whole development process', '8.10 system hardware faults hardware for ai systems needs to have robust fault tolerance', 'far more insidious are faults that cause unit to produce reasonable looking but incorrect outputs or that cause component to act maliciously. these faults are soft errors unwanted temporary state changes of memory cells or logic components that are usually caused by high-energy radiation from sources such as alpha particles from package decay neutrons and external emi effects like electromagnetic noise and electromagnetic beams but can also be caused by internal cross talk between conductor paths or component parts or malicious injection of perturbations such as clock glitches']"
1,34,1_data_learning_hyper_challenge,"['data', 'learning', 'hyper', 'challenge', 'tasks', 'training', 'algorithms', 'modelling', 'retrain', 'updating']","['the model is continuously updated by learning from new data', 'other approaches to model selection and development include transfer learning which aims to leverage knowledge of one task to learn new task and federated learning which aims to learn new models in distributed and collaborative manner', 'model is the representation of machine learning algorithm when trained with data']"
2,32,2_causal_levels_decisions_explanations,"['causal', 'levels', 'decisions', 'explanations', 'explainability', 'features', 'credit', 'validity', 'attributions', 'qualitative']","['full explanation of an ai system can therefore consist of all the following features the chain of causal attributions which track how the algorithm produces decision the functional roles of the measured features in the modelled phenomenon the ethical and other principles and standards by which an algorithmic output is justified', '9.3.5.2 causal explanation how something functions for the goal of understanding how an ai system arrives at its results an explanation consists of chain of causal attributions explaining the mechanisms by which the input features are processed to produce the given result', 'for example the high saliency of gender feature in the result of credit decision algorithm gives partial causal explanation of how the algorithm produced the decision but it does not answer the questions of what functional role gender plays in one credit-viability or by what standards it is valid to justify credit-decision on that basis']"
3,31,3_transparency_explainability_external_stakeholder,"['transparency', 'explainability', 'external', 'stakeholder', 'inspection', 'features', 'procedures', 'rating', 'stakeholders', 'assurance']","['transparency makes the data features algorithms and training methods available to external inspection', 'transparency involves making data features models algorithms training methods and quality assurance processes available for external inspection', 'transparency of ai systems relates to making the data features algorithms training methods and quality assurance processes available to external inspection by stakeholder']"
4,29,4_risk_harm_risks_uncertainty,"['risk', 'harm', 'risks', 'uncertainty', 'hazards', 'threats', 'precautionary', 'objectives', 'consequences', 'stakeholders']","['these include approaches to quality both metrics and measurement methodologies safety and risk of harm and risk management frameworks such as those existing for security and privacy', 'the general process of risk management is defined in iso 31000:2018 and involves identifying stakeholders and their vulnerable assets and values assessing associated risks with their consequence or impact and making conscious risk treatment decisions based on the organization objectives and its risk tolerance', 'in safety engineering process for capturing and then sizing stakeholder value requirements includes the understanding of the system context of use the risks of harm and when applicable an application of the precautionary principle as risk mitigation technique against potential unintended consequences such as harm to rights and freedom of natural persons life of any kind the environment species or community']"
5,27,5_privacy_data_metrics_threats,"['privacy', 'data', 'metrics', 'threats', 'evaluate', 'anonymity', 'intrusion', 'defining', 'adversary', 'protection']","['the advantage of privacy metrics is the ability to compare different privacy-preserving techniques evaluate different methods within specific domain and to minimize the privacy exposure', '9.10.4 privacy-related considerations in addressing privacy threats in ai privacy metrics help to evaluate levels of privacy and amount of protection provided by the system', 'the purpose of defining privacy metrics is to quantify the data privacy level that results in improving the privacy model within specific ai model']"
6,27,6_testing_trials_software_tests,"['testing', 'trials', 'software', 'tests', 'validation', 'empirical', 'practices', 'oracle', 'clinical', 'evaluation']","['9.10.2.6 field trials due to the difference between testing environments and actual operating conditions field trials are often very effective way to improve the quality of the deployed system by testing its performance efficiency or durability', '30\x08 9.10.2.3 empirical testing various techniques exist for empirical testing of non-deterministic solutions for the purpose of software validation and verification including metamorphic testing technique that establishes relationships between inputs and outputs of the system and relies on running multiple iterations of testing and comparing the results', 'software systems are also subjected to formal software validation verification and testing methods such as defined in reference the primary goals of software tests are stated in reference provide information about the quality of the test item and any residual risk in relation to how much the test item has been tested to find defects in the test item prior to its release for use and to mitigate the risks to the stakeholders of poor product quality. by design ai systems are often less deterministic than traditional software systems and rarely exhaustively explainable']"
7,26,7_trustworthiness_trust_organizational_requirement,"['trustworthiness', 'trust', 'organizational', 'requirement', 'safety', 'cyber', 'attributes', 'security', 'reliability', 'integrity']","['regarding the layer of physical trust the concept is often synonymous to the combination of reliability and safety because the metrics are based on physical measurement or test', 'in summary trustworthiness has been understood and treated as both an ongoing organizational process as well as non-functional requirement', 'for example the itu-t report on trust provisioning introduces three layers of trust physical trust cyber trust and social trust taking into account the physical infrastructure for data collection e.g']"
8,22,8_trustworthiness_trust_surveys_discusses,"['trustworthiness', 'trust', 'surveys', 'discusses', 'layer', 'safe', 'establish', 'fairness', 'applications', 'pedagogical']","['the document briefly surveys the existing approaches that can support or improve trustworthiness in technical systems and discusses their potential application to ai systems', 'in clause the document briefly surveys existing approaches being used for building trustworthiness in technical systems and discusses their potential applicability to ai systems', 'vi\x08 information technology artificial intelligence overview of trustworthiness in artificial intelligence scope this document surveys topics related to trustworthiness in ai systems including the following approaches to establish trust in ai systems through transparency explainability controllability etc']"
9,21,9_epistemic_explanations_causal_justificatory,"['epistemic', 'explanations', 'causal', 'justificatory', 'explainability', 'arguments', 'reversal', 'redress', 'seeking', 'understandability']","['9.3.5.3 epistemic explanation how we know it functions for the goal of epistemic justification that is explanation of why an algorithmically produced result is true successful explanation tracks the functional or logical relationships in the modelled phenomenon', 'an attempt to explain can offer multiple different but equally valid modes of explanation depending on whether stakeholders seek causal understanding of how result is arrived at an epistemic understanding of the knowledge on which the result is based or justificatory understanding of the grounds in which the result is offered as being valid', 'these three modes of explanation can be distinct as an organization can produce causal explanation without having produced an epistemic or justificatory explanation']"
10,21,10_consideration_technologies_robot_task,"['consideration', 'technologies', 'robot', 'task', 'expect', 'range', 'eroded', 'disposal', 'recommendation', 'industrial']","['the ai system application its intended use and reasonably foreseeable misuse as well as the environment in which it is used and the technologies that are used become subject to careful consideration', 'such an approach allows for the following ai systems users and stakeholders can expect that the ai system quality while performing an information processing task are not worse than the quality of the solution of the same problem performed by human-operator third parties can expect that the operation of an ai system will not cause damage to people and material goods', 'the time saved by the user of product or service employing ai or time wasted in reacting to an inappropriate recommendation from an ai system skills which can become less valued due to automation enabled by an ai system autonomy which can be enhanced by more efficient provision of task related information by an ai system or which can be eroded e.g']"
11,19,11_bias_strategies_lead_business,"['bias', 'strategies', 'lead', 'business', 'classification', 'groups', 'application', 'examples', 'data', 'processes']","['selection bias sampling bias coverage bias or simply technical errors', 'bias typically arises from sources including human cognitive bias societal bias and statistical bias e.g', '9.5 strategies for reducing bias many strategies exist to address bias consideration of legal and other requirements relating to bias can be explicitly identified when defining system requirements including setting appropriate thresholds analysis of the provenance and completeness data sources can reveal risks and the processes used to collect or annotate data can be reviewed technical techniques can be used as part of model training processes to detected and mitigate bias specific testing and evaluation techniques can be used to detect bias trials or regular operational reviews can be used to detect bias related issues in the actual context of use']"
12,19,12_attacks_adversarial_attack_poisoning,"['attacks', 'adversarial', 'attack', 'poisoning', 'ml', 'defences', 'security', 'attackers', 'training', 'perturbed']","['such threats include the following data poisoning that results in malfunctioning ai system adversarial attacks that abuse benign ai system and model stealing', 'have shown that computer vision ml algorithms in particular deep neural networks can be susceptible to attacks based on adversarial examples or adversarial perturbations', '8.2.3 adversarial attacks one particular security threat associated with ai systems is the adversarial attack on the machine learning systems']"
13,18,13_trustworthy_ethics_values_european,"['trustworthy', 'ethics', 'values', 'european', 'societal', 'moral', 'innovation', 'worldviews', 'ethical', 'principles']","['the european group on ethics in science and new technologies highlighted in their statement that an ai-driven system can not be autonomous in the legal sense and clear framework of responsibility and legal liability needs to be established to enable recourse for any harm caused by the operation of any autonomous system', 'annex informative related work on societal issues in addressing the trustworthiness of ai in relation to societal issues large body of multidisciplinary work exists already including technology ethics research and innovation ethics often referred to as responsible research and innovation accountable algorithms and data ethics and data protection within data governance', 'some proposals for trustworthy ai are grounded in specific set of values established in particular policy such as the european commission high level expert group working paper on trustworthy ai which proposes principles grounded in the european charter of fundamental rights']"
14,18,14_inputs_robustness_ability_classification,"['inputs', 'robustness', 'ability', 'classification', 'range', 'correlates', 'interpolation', 'metrics', 'score', 'reliable']","['this means that in the case of unknown inputs and outputs it is expected that the ai system assigns score that is not radically different from score being assigned to known inputs and unknown inputs as long as they are not too different from the known inputs', 'when an ai system is used to perform scoring its robustness is viewed as the ability to assign consistent confidence measures of ranking on both known inputs and inputs within an acceptable range', 'when an ai system is used to perform classification its robustness is viewed as its ability to assign consistent classification on both known inputs and inputs within certain range']"
15,18,15_specification_phase_objective_provision,"['specification', 'phase', 'objective', 'provision', 'requirements', 'verify', 'functionality', 'failures', 'fidelity', 'misinterpretations']","['according to reference validation is confirmation through the provision of objective evidence that the requirements for specific intended use or application have been fulfilled', '3.44 validation confirmation through the provision of objective evidence that the requirements for specific intended use 3.22 or application have been fulfilled note to entry the right system 3.38 was built', 'note the right system was built. verification is the confirmation through the provision of objective evidence that specified requirements have been fulfilled']"
16,17,16_resilience_reliability_robustness_automation,"['resilience', 'reliability', 'robustness', 'automation', 'ability', 'misuse', 'reliance', 'attributes', 'expectations', 'publication']","['according to reference it is possible to group these factors into four main categories use when automation enables humans to achieve their goals misuse when over-reliance on automation perpetrates an unforeseen negative outcome', 'ability can be described as system characteristic to perform specific task and can be assessed in terms of several attributes including reliability resilience and robustness', 'for example misuse would be the individual being too reliant on automation and not paying attention to the road disuse when under-reliance on automation perpetrates negative outcome']"
17,17,17_stakeholder_stakeholders_rri_organization,"['stakeholder', 'stakeholders', 'rri', 'organization', 'individuals', 'value', 'responsibilities', 'accountability', 'assets', 'objectives']","['technical report\x08 3.5 asset anything that has value 3.46 to stakeholder 3.37 note to entry there are many types of assets including information 3.20 software such as computer program physical such as computer services people and their qualifications skills and experience and intangibles such as reputation and image', 'in business stakeholder theory highlights the benefit of an approach to decision-making that looks beyond the fiduciary obligation of management to generate profits for shareholders and considers benefits to other types of stakeholders in an organization including employees customers management suppliers creditors government and regulators society in general and the natural environment as proxy representing future generations', 'stakeholders 6.1 general concepts this document adopts broad definition of stakeholders from iso/iec which in addition to recognizing individuals and organizations acknowledges group of people as type of stakeholder which is important when understanding the collective viewpoints shared by population of individuals that does not constitute an organization i.e']"
18,14,18_source_entry_note_modified,"['source', 'entry', 'note', 'modified', '51', 'ieee', 'entity', 'property', 'guide', 'protecting']","['source iso/iec/ieee 15288:2015 3.38 3.39 threat potential cause of an unwanted incident which may result in harm 3.17 to systems 3.38 organizations or individuals 3.40 training process 3.29 to establish or to improve the parameters of machine learning model 3.24 based on machine learning algorithm 3.3 by using training data 3.11 3.41 trust degree to which user 3.43 or other stakeholder 3.37 has confidence that product or system 3.38 will behave as intended source iso/iec 25010:2011 4.1.3.2 3.42 trustworthiness ability to meet stakeholders 3.37 expectations in verifiable way note to entry depending on the context or sector and also on the specific product or service data 3.11 and technology used different characteristics apply and need verification 3.47 to ensure stakeholders expectations are met', ""3.15 efficiency relationship between the results achieved and the resources used source iso 9000:2015 3.7.10 3.16 entity any concrete or abstract thing of interest source iso/iec 10746-2:2009 6.1 3.17 harm injury or damage to the health of people or damage to property or the environment source iso/iec guide 51:2014 3.1 3.18 hazard potential source of harm 3.17 source iso/iec guide 51:2014 3.2 3.19 human factors environmental organizational and job factors in conjunction with cognitive human characteristics which influence the behaviour of persons or organizations 3.20 information meaningful data 3.11 source iso 9000:2015 3.8.2 3.21 integrity property of protecting the accuracy and completeness of assets 3.5 source iso/iec 27000:2018 3.36 modified in the definition `` protecting the '' has been added before `` accuracy '' and `` of assets '' has been added after `` completeness ''"", 'source iso 18646-2:2019 3.1 3.33 robotics science and practice of designing manufacturing and applying robots 3.32 source iso 8373:2012 2.16 3.34 safety freedom from risk 3.31 which is not tolerable source iso/iec guide 51:2014 3.14 3.35 security degree to which product or system 3.38 protects information 3.20 and data 3.11 so that persons or other products or systems have the degree of data access appropriate to their types and levels of authorization source iso/iec 25010:2011 4.2.6 3.36 sensitive data data 3.11 with potentially harmful effects in the event of disclosure or misuse source iso 5127:2017 3.1.10.16 3.37 stakeholder any individual group or organization that can affect be affected by or perceive itself to be affected by decision or activity source iso/iec 38500:2015 2.24 3.38 system combination of interacting elements organized to achieve one or more stated purposes note to entry system is sometimes considered as product or as the services it provides']"
19,14,19_validation_dataset_model_testing,"['validation', 'dataset', 'model', 'testing', 'subsets', 'tuned', 'set', 'train', 'sensitivity', 'split']","['finally the test dataset is used during the testing phase in order to provide final evaluation of the trained fit and tuned model', 'the simple model validation technique uses only one validation dataset', '8.8.2.5 model validation evaluation after having tuned the models these are evaluated against the validation datasets in order to check their performance on data that is different from the dataset used for training']"
20,13,20_service_stakeholder_organization_assets,"['service', 'stakeholder', 'organization', 'assets', 'stakeholders', 'value', 'international', 'tools', 'roles', 'develop']","['tangible assets specific to ai can include data used to train an ai system trained ai system product or service that uses one or more ai system data used to test the ai-related behaviour of product or service data fed to product or service operation based on which ai-based decisions are made computing resources and software used to train test and operate ai systems human resources with the skills to train test and operate ai systems develop software used in or for those tasks and/or generate annotate or select data needed for ai training', 'such stakeholder communication would address how different stakeholder can be affected by ai technology deployed in product or service how any assets that are valued by different stakeholder are used or affected by the use of ai in product or service how the use of ai in product or service relates to values held by different stakeholders', 'in the context of ai we can consider such stakeholder types in relation to the following distinct roles in the ai value chain noting that single stakeholder can undertake several such roles data source an organization or an individual providing data that is used to train an ai system ai system developer an organization or an individual that designs develops and trains an ai system ai producer an organization or an individual that designs develops tests and deploys product or service that uses at least one ai system ai user an organization or an individual that consumes product or service that uses at least one ai system ai tools and middleware developer an organization or an individual that design and develop ai tools and pretrained ai building blocks test and evaluation agency an organization or an individual that offer independent testing and possibly certification the broader society in which the ai system is deployed as even an accurate ai system can lead to confirmation of existing inequalities associations representing the viewpoints of individuals governance organizations that monitor and study the usage of ai including national governments and international organizations such as the international monetary fund imf']"
21,12,21_vulnerabilities_security_threats_learning,"['vulnerabilities', 'security', 'threats', 'learning', 'ml', 'address', 'deployment', 'advances', 'backdoors', 'breaches']","['the recent impressive advances in the field of ml especially in the area of deep learning have led to an increased interest in companies to apply ml algorithms in safety-critical and security-critical application contexts', 'challenges related to the lack of best practices for design development and deployment of ai systems can introduce additional or exacerbate existing vulnerabilities and threats', 'vulnerabilities threats and challenges 8.1 general this clause describes potential vulnerabilities of ai systems and the threats associated with them']"
22,12,22_confidentiality_integrity_memory_execution,"['confidentiality', 'integrity', 'memory', 'execution', 'hardware', 'attacks', 'applications', 'platforms', 'protected', 'securely']","['typical software and hardware attacks on machine learning applications are digital attacks affecting confidentiality of the data and integrity of data and computation', 'hardware mechanisms reduce an attack surface by providing trusted execution environments tees which protect confidentiality and integrity of both the data and computation and for both training and use', 'ensuring confidentiality and integrity of data and code via traditional mechanism such as memory integrity and trusted platform modules included in tees is necessary but not sufficient to ensure confidentiality and integrity of the code and data of the machine learning engines enforcing that the execution of the ml programs follows the programmed-intended logic is equally critical']"
23,10,23_target_leakage_overfit_predicted,"['target', 'leakage', 'overfit', 'predicted', 'feature', 'dataset', 'underfitting', 'overfitting', 'learned', 'underfit']","['this can happen for example when the training data includes information that is not available at the time of the prediction since the corresponding variable/feature is updated only after the target value is predicted', 'an overfit model is model that has learned too many details and is so tightly fit to the underlying data set including its noise or inherent error in the dataset that it performs poorly at making predictions when new data comes in', '8.8.2.3 model training target leakage also called data leakage occurs when the training dataset contains some information related to the variable being predicted target variable that would not be the case in production']"
24,10,24_cloud_devices_applications_implemented,"['cloud', 'devices', 'applications', 'implemented', 'tenant', 'pruning', 'gpu', 'fpgas', 'virtualized', 'accelerators']","['cloud and end- applications e.g', 'ai applications are deployed on systems that range from end devices mainly used for inference to cloud-class compute and storage resources used for both inference and training', 'in many cases these accelerators or devices can be para- virtualized or emulated and in some cases cloud-based applications can benefit from using devices directly assigned to them']"
25,10,25_safety_equipment_electronic_operating,"['safety', 'equipment', 'electronic', 'operating', 'implementing', 'comprehensive', 'priority', 'fail', 'elements', 'sector']","['the aspect of the overall system that depends on system or equipment operating correctly in response to its inputs is generally known as functional safety', 'iec sets out generic approach for all safety lifecycle activities for systems comprised of electrical and/or electronic and/or programmable electronic elements that are used to perform safety functions', '9.9 functional safety to ensure functional safety of system specific functionality can be introduced that performs safety related aspects']"
26,9,26_predictability_robot_acceptability_actions,"['predictability', 'robot', 'acceptability', 'actions', 'interaction', 'questionnaire', 'indirect', 'intention', 'gaze', 'experiments']","['similarly for the acceptability of collaborative robots in direct interaction with humans human operators need to be able to predict robot behaviour to ensure operators safety', 'the gaze behaviour also gives an indirect indication of the robot predictability assuming that the more often and the longer the robot is watched by participant the less it is predictable', 'predictability can be measured through subjective explicit feedback from questionnaire- based experiments where participants are asked to infer the goals and predict the future actions of robot for example']"
27,9,27_quality_characteristics_structured_software,"['quality', 'characteristics', 'structured', 'software', 'defines', 'governance', 'guides', 'portability', 'railway', 'automotive']","['the square series have been developed for traditional software systems that store their data in structured manner and process it using explicit logic', 'iso/iec is part of the square series of international standards and describes model consisting of characteristics and sub-characteristics for software product quality and software quality in use', 'the iso/iec square series deals with software quality through models and measurement iso/iec 2501x on models and iso/iec 2502x on measurement resulting in list of characteristics for software quality and characteristics for data quality']"
28,9,28_feature_features_change_predictive,"['feature', 'features', 'change', 'predictive', 'importance', 'predictions', 'proportionally', 'selectivity', 'removal', 'strongest']","['that is the removal of feature or set of features with highest relevance score would result in sharp change in the model output', '8.8.2.2 feature engineering in machine learning feature is an input variable that is used by the model to make predictions', 'this includes considering the following aspects continuity for which the associated explanation for the predictions of nearby points would be nearly equivalent consistency where if we change the model such that the contribution of certain feature on the predicted output is increased the importance-score of that feature estimated by the explainability method would not be decreased selectivity where for importance-based explanations it is desirable that the contribution score be distributed among the features that have the strongest impact on the generated prediction']"
29,8,29_source_skills_knowledge_terms,"['source', 'skills', 'knowledge', 'terms', 'definitions', 'entity', 'entry', 'education', 'reorganizing', 'neurons']","['3.29 process set of interrelated or interacting activities that use inputs to deliver an intended result source iso 9000:2015 3.4.1 modified the notes to entry have been omitted', '3.2 actor entity 3.16 that communicates and interacts source iso/iec tr 22417:2017 3.1 3.3 algorithm set of rules for transforming the logical representation of data 3.11 source iso/iec 11557:1992 4.3 3.4 artificial intelligence ai capability of an engineered system 3.38 to acquire process and apply knowledge and skills note to entry knowledge are facts information 3.20 and skills acquired through experience or education', 'source iso/iec guide 51:2014 3.6 3.23 machine learning ml process 3.29 by which functional unit improves its performance by acquiring new knowledge or skills or by reorganizing existing knowledge or skills source iso/iec 2382:2015 3.24 machine learning model mathematical construct that generates an inference or prediction based on input data 3.11 3.25 neural network computational model utilizing distributed parallel local processing and consisting of network of simple processing elements called artificial neurons which can exhibit complex global behaviour source iso 18115-1:2013 8.1 3.26 pattern set of features and their relationships used to recognize an entity 3.16 within given context source iso/iec 2382:2015 3.27 personal data data 3.11 relating to an identified or identifiable individual source iso 5127:2017 3.1.10.14 modified the admitted terms and notes and to entry have been removed']"
30,8,30_autonomous_vehicles_driving_characteristic,"['autonomous', 'vehicles', 'driving', 'characteristic', 'self', 'traffic', 'judgments', 'oversight', 'streets', 'vacuum']","['allowing autonomous vehicles to drive on city streets or an autonomous system to make any treatment would happen only if there is an evidence that the ai system conducting these activities performs not worse than human', 'the use of ai in autonomous vehicles is an obvious use case as the widespread adoption of ai-based autonomous vehicles is likely predicated on the ability of such vehicles to behave in predictable fashion', 'for instance self-driving car can collide with non-autonomous car because of the inability of human driver to discern the future actions of the autonomous car and vice versa']"
31,8,31_quality_standards_standardization_prevalence,"['quality', 'standards', 'standardization', 'prevalence', 'extending', 'efforts', 'provenance', 'adequately', 'community', 'isolation']","['the prevalence of this issue in ai systems suggests that new standardization efforts can be initiated to encourage new verification and validation techniques', 'in addition data quality model for ai systems needs to take into consideration other characteristics not currently described in iso/iec such as bias in the data used to develop the ai system', 'to more adequately cover ai systems and the data they depend on it is possible that there is need for extending or modifying existing standards to go beyond the characteristics and requirements of traditional systems and software development described in iso/iec and the data quality model described in iso/iec']"
32,8,32_data_inferences_reconstruct_sharing,"['data', 'inferences', 'reconstruct', 'sharing', 'agreements', 'duplications', 'entities', 'raw', 'normalization', 'documented']","['risk of re-identification after analysing data from multiple data sources', 'although the data is de-identified it is possible that ai re-identifies data using the inferences based on the data from the other sources', 'even when the data is de-identified when personal data is available from multiple sources it is possible for ai to re-identify the data using the inferences based on the data from the other sources']"
33,8,33_hci_confidence_processing_interaction,"['hci', 'confidence', 'processing', 'interaction', 'capabilities', 'impersonate', 'demonstrate', 'intellect', 'handwriting', 'automate']","['as result keeping human factors in view it is best to take nuanced view of optimizing these metrics in human-facing ai systems', '9.10.2.7 comparison to human intelligence in cases when an ai system is designed to automate human activity associated with data processing and decision-making one of the ways to validate an ai system is by comparison to human intelligence capabilities', '8.9 challenges related to the use of ai systems 8.9.1 human-computer interaction hci factors there are many pitfalls that are based on human relating factors']"
34,8,34_properties_explanations_concentrates_evidenced,"['properties', 'explanations', 'concentrates', 'evidenced', 'circumstances', 'establishing', 'features', 'trust', 'consistency', 'algorithmic']","['that is while ex-ante explanation is important for establishing trust in the ai system it is impossible to achieve system transparency without access to ex-post explanation as well', 'ex-ante and ex-post explanations serve different functions', '9.3.3 ex-ante vs ex-post explanation ex-ante explains the general properties and features of system before use of said system']"
