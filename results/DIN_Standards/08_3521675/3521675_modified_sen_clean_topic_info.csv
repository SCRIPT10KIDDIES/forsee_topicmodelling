Topic,Count,Name,Representation,Representative_Docs
-1,60,-1_calibration_uncertainty_predictor_spec,"['calibration', 'uncertainty', 'predictor', 'spec', 'logistic', 'stemming', 'beta', 'observations', 'bias', 'temperature']","['categorical din spec table continued method name short description type of ml model output reference temperature scaling temperature scaling is similar to the logistic calibration function but only using single rescaling parameter temperature for all possible classes and without any bias term', 'categorical beta calibration this method is related to the logistic calibration function but is derived using beta distribution for the rescaling and bias parameters since this method asserts the input score to be already defined in the interval', 'table overview of aleatoric and epistemic uncertainty aleatoric uncertainty grey area epistemic uncertainty source stemming from the stochasticity in the observation sensor noise or the generating process stemming from the lack of measures independent features stemming from the domain or application shift out of distribution application stemming from the hypothesis space mismatch to insufficient problem understanding model structure mismatch feature transformation stemming from the error in model parameters stemming from the lack of observations underfitting or overfitting lack of generalization mitigation can not be reduced by enhancing the learning process and collecting observations can only be reduced from the view of engineering can be reduced by enhancing the learning process and collecting observations din spec annex informative exemplary uncertainty calibration metrics and methods an overview about different metrics for measuring uncertainty calibration see is given in table']"
0,48,0_fusion_sensor_gps_pod,"['fusion', 'sensor', 'gps', 'pod', 'detection', 'drone', 'ekf', 'imu', 'classification', 'score']","['system definition the sensor measurements used for the sensor fusion were as follows imu sensor specific force and angular rates using accelerometers and gyroscopes respectively gps position and linear velocity magnetometer magnetic flux barometer altitude probabilistic object detection pod outputs', 'the estimated states figure during the landing phase from to on the is plotted without and with fusion of pod outputs during gps outage', 'din spec key without pod fusion with pod fusion gps outage pod fusion time gps position position position error position position error true estimated figure exemplary drone state and uncertainty evolution without and with pod fusion over time examples of requirements and recommendations for this use case the requirements and recommendations were applied the total uncertainty of the detection outputs was']"
1,47,1_uncertainty_approaches_statistical_confidence,"['uncertainty', 'approaches', 'statistical', 'confidence', 'knowledge', 'quantifications', 'numerical', 'teacher', 'safety', 'uncertainties']","['note to include properties of an uncertainty quantification approach see also', 'statistical confidence uncertainty quantification approaches shall provide uncertainty quantification with statistical confidence statement that takes the basis of their determination into account', 'in examples for properties of uncertainty quantification approaches are given']"
2,27,2_quantification_uncertainty_applications_stakeholders,"['quantification', 'uncertainty', 'applications', 'stakeholders', 'responsibility', 'requirements', 'factors', 'terminology', 'dependable', 'approaches']","['description since default solutions for uncertainty quantifications such as using the ml model results on the softmax layer do not provide rable uncertainty estimates one solution can be to use dedicated uncertainty wrapper that is responsible for uncertainty quantification figure', 'this document provides an overview of available uncertainty quantification approaches in ml and their racteristics and describes selected applications', 'to address this issue this document nes essential terminology clause introduces important aspects of uncertainty quantification clause describes selected applications of uncertainty quantification clause provides an overview of uncertainty quantification approaches and general characteristics clause as well as formulates requirements and dnes for uncertainty quantification in ml clause']"
3,26,3_transfer_tools_techniques_inputs,"['transfer', 'tools', 'techniques', 'inputs', 'trained', 'dataset', 'categories', 'software', 'knowledge', 'development']","['transfer learning transfer learning refers to methods used to abstract knowledge gained from data used for solving one problem to apply it on different task further can be found in', 'example most existing unsupervised domain adaptation methods of transfer learning suffer from negative transfer of learning from the source to the target domain', 'summarizes ml algorithms tools for data preparation optimization methods and ml evaluation metrics as software tools and techniques']"
4,26,4_random_events_entry_measure,"['random', 'events', 'entry', 'measure', 'sample', 'values', 'distribution', 'representations', 'sequence', 'sigma']","['random variable function defined on sample space where the values of the function are ordered of real numbers note to entry an example of an ordered is xk', 'note to entry random variable is function defined on the sample space that is part of probability space', 'note to entry since random variable is function on subsets of the sample space to the real line it is the case for example that the probability that random variable takes on any real value is']"
5,24,5_sign_traffic_tsr_recognition,"['sign', 'traffic', 'tsr', 'recognition', 'type', 'precipitation', 'images', 'factors', 'classifying', 'probability']","['example in the application of traffic sign', 'example for example tsr model would process an input image to classify the traffic sign visible in the image as stop sign', 'example simplistic traffic sign classification considers three different classes stop sign speed limit sign and no traffic sign']"
6,24,6_terms_entry_modified_document,"['terms', 'entry', 'modified', 'document', 'references', 'automation', 'terminological', 'databases', 'german', 'addresses']","['source din iso modified example was removed and for the battery example was deleted from note to entry', 'information technology artificial intelligence artificial intelligence concepts and terminology din iso statistics vocabulary and symbols part general statistical terms and terms used in probability iso text in german and english terms and definitions for the purposes of this document the terms and definitions given in din iso and the apply', 'din spec operational design domain odd target application scope tas intended operational conditions intended operational domain operating conditions under which given or feature thereof is specifically designed to function ding but not limited to environmental geographical and restrictions note to entry the term is strongly related to and can sometimes be interchangeable to terms that are used outside the automotive context for similar purposes intended iso or target application scope defined as common conditions under which the ml model is intended to be applied source sae modified terms driving automation and the requisite or absence of certain traffic or roadway characteristics removed data data from distribution different from the distribution of data used during model development including training validation calibration or testing data set note to entry often the data is encountered outside of the operational design domain']"
7,20,7_transparency_tree_human_process,"['transparency', 'tree', 'human', 'process', 'semantic', 'dependability', 'algorithmic', 'interpretability', 'uncertainty', 'relationships']","['confidence statistical confidence level of trust in the statistics or certainty confidence level value of the probability associated with confidence interval or statistical coverage interval source guide modified note to entry was deleted decomposability model property of the model which enables the human to comprehend each of the model parts without the need of tools dependability of an item ability to perform as and when required note to entry dependability includes availability rability recoverability maintainability and maintenance support performance and in some cases other characteristics such as durability safety and security', 'four decision levels can be as highly transparent model since it is algorithmic transparent since the underlying concepts as binary decision making using gain as criteria is mathematically well understood decomposable since the inputs and variables and thresholds used in each node of the tree are human comprehensible simulatable since humans can follow up the complete decision making process and calculate the model results for given input by themselves by applying at most four comparisons', 'rability degree to which product or component performs specified functions under specified conditions for specified period of time source modified notes to entry were deleted uncertainty uncertainty caused by the possibility that the ml model provides an output although it is applied outside its operational design domain simulatability model property of the model which enables the human to fully simulate the model and recreate the model outputs without the need of tools din spec set of interrelated or interacting elements source din iso transparency model degree to which interpretability is supported through algorithmic transparency decomposability and simulatability of the model note to entry this definition is on the domains of interpretability introduced by']"
8,20,8_operational_quality_vehicle_level,"['operational', 'quality', 'vehicle', 'level', 'altitude', 'uncertainty', 'validity', 'tem', 'adaptive', 'thresholds']","['the strategy of should be adaptive with respect to different situations in the operational design domain', 'the uncertainty quantification was sensitive to the vehicle altitude in the operational design domain', 'if uncertainty thresholds are used as part of the strategy in they shall be defined inside the operational design domain']"
9,18,9_calibration_confidence_accuracy_uncalibrated,"['calibration', 'confidence', 'accuracy', 'uncalibrated', 'uncertainty', 'classification', 'calibrated', 'rability', 'quality', 'realism']","['this accuracy score is finally used to reassign new confidence score to sample which depends on the original uncalibrated confidence estimate', 'according to the definition of calibration in and classification ml model is if the predicted uncertainty matches the accuracy conditioned on the estimated probability scores', 'the calibration property can be measured by using the expected calibration error ece which approximates the observed accuracy conditioned on the estimated probability scores by binning scheme over the confidence space']"
10,15,10_probabilistic_models_weights_gaussian,"['probabilistic', 'models', 'weights', 'gaussian', 'mixture', 'svm', 'features', 'logistic', 'classification', 'examples']","['probabilistic models one way of classifying ml models is to distinguish between probabilistic and approaches', 'example deep neural network with million weights using the internal log ges with unknown meaning as features can be as largely intransparent model since it has limited algorithmic transparency using approaches as stochastic gradient descent to determine the weights for its calculations limited decomposability since the meaning of the model features is not semantically clear and is not simulatable to the millions of individual calculations and weights that need to be', 'the list shows examples of probabilistic models linear models such as logistic regression kernel methods such as deep gaussian processes probabilistic graphical models bayesian neural networks note while neural network classifiers in general provide probabilistic outputs in form of class scores tributed across the labels regression outputs are usually limited to estimates']"
11,15,11_ece_accuracy_categorical_calibration,"['ece', 'accuracy', 'categorical', 'calibration', 'binning', 'predicted', 'uce', 'diagram', 'computed', 'approximation']","['din spec table common uncertainty calibration methods for the correction of possibly uncalibrated uncertainty estimates of an ml model for categorical and continuous random variables method name short description type of ml model output reference histogram binning approximation of the distribution for observed accuracy with respect to the predicted confidence by applying binning scheme over the confidence space similar to the computation of the ece metric', 'categorical average calibration error this metric uses similar binning scheme as the ece but returns the unweighted sum of absolute differences between observed accuracy and average confidence in each bin', 'table common metrics for measuring uncertainty calibration of an ml model for categorical and continuous random variables metric name short description type of ml model output reference expected calibration error ece approximation of the distribution for observed accuracy with respect to the predicted confidence by applying binning scheme over the confidence space']"
12,14,12_uncertainty_context_entry_concept,"['uncertainty', 'context', 'entry', 'concept', 'feature', 'outputs', 'epistemic', 'models', 'training', 'prediction']","['certainty bef that statement on an ml model output is correct note to entry the statement refers to the model output itself or statement created using the output', 'uncertainty ml lack of certainty note to entry uncertainty in statement can be caused by both that indicates that the statement can be wrong and ii insufficient that can justify its correctness', 'note causes of uncertainty can be aleatoric caused by the inherent stochastic nature of the phenomena of interest or noise in the data collection or epistemic caused by insufficient training data to accurately model the phenomena or inappropriate model training']"
13,14,13_operational_metrics_performance_empirical,"['operational', 'metrics', 'performance', 'empirical', 'evaluation', 'dataset', 'application', 'training', 'build', 'visibility']","['it is commonly estimated by determining the validity of the ml model on test dataset that is appropriate for this purpose which includes that the data is representative for the operational design domain and independent of the data used to build the ml model', 'the performance of the ml model is usually measured by one or more performance metrics that are collected on test dataset that is representative of the operational design domain', 'since ml models are empirical models that are trained and tested on data collected for an operational design domain statistical results on their outputs are only meaningful in their operational design domain']"
14,14,14_quantiles_quantile_isotonic_regression,"['quantiles', 'quantile', 'isotonic', 'regression', 'calibration', 'qce', 'frequency', 'measures', 'translation', 'population']","['continuous quantile calibration error qce the qce evaluates how closely the predicted quantiles match the true quantiles of the target variable', 'if only the quantiles of the calibrated distribution are of interest the isotonic regression or method is advantageous', 'the target of isotonic regression for continuous random variables is to achieve quantile calibration']"
15,13,15_binning_sets_methods_histogram,"['binning', 'sets', 'methods', 'histogram', 'scaling', 'overfit', 'distributions', 'approximation', 'samples', 'bin']","['compared to binning methods such as histogram binning this method only has limited representational power', 'compared to binning methods such as histogram binning this method only has limited representational power', 'compared to binning methods such as histogram binning this method only has limited representational power']"
16,12,16_scaling_variance_normal_parametric,"['scaling', 'variance', 'normal', 'parametric', 'method', 'gp', 'distributions', 'parameter', 'rescale', 'temperature']","['thus this method also adapts gp to yield an scaling parameter for the variance of normal distribution and aims to achieve variance calibration but in an fashion', 'if parametric distribution is required normal distribution either variance scaling or gaussian process gp is advantageous', 'if parametric distribution is required normal distribution either variance scaling or is advantageous']"
17,10,17_ontology_uncertainty_epistemic_types,"['ontology', 'uncertainty', 'epistemic', 'types', 'categorization', 'taxonomy', 'compliance', 'scope', 'ambiguity', 'forests']","['din spec annex informative types of uncertainty aleatoric and epistemic table expands upon the definition of aleatoric and epistemic uncertainty and clarifies the grey area where the types are ambiguous', 'din spec uncertainty in machine learning ontology figure overview of uncertainty quantification ontology din spec this section introduces an ontology that relates the key terms used in this document', 'each taxonomy includes collection of types for categorizing causes that share certain common features this document uses the distinction between aleatoric and epistemic uncertainty see annex and the distinction between model fit input quality and scope compliance uncertainty see']"
18,9,18_dropout_uncertainty_models_monte,"['dropout', 'uncertainty', 'models', 'monte', 'memory', 'probabilistic', 'wrappers', 'lists', 'encompass', 'wasserstein']","['uncertainty quantification methods are understood as methods that can be applied to existing probabilistic and ml models to estimate uncertainty', 'uncertainty quantification methods introduction while using probabilistic models can by itself be viewed as method to quantify uncertainty in ml babilistic models are to be distinguished from uncertainty quantification methods', 'methods uncertainty quantification methods encompass specialized techniques with many examples stemming from the field of deep learning dl such as approaches see monte carlo dropout or concrete dropout methods extending the approach to model aleatoric uncertainty see loss attenuation or wasserstein dropout approaches utilizing dirichlet distribution see']"
19,8,19_ood_detection_identify_methods,"['ood', 'detection', 'identify', 'methods', 'changes', 'distribution', 'occurrences', 'influence', 'anomaly', 'order']","['detection ood detection is an approach to identify if an ml model is applied on data that do not follow the distribution for which the model was intended to be applied and thus trained and tested', 'since ood occurrences can have different causes there exist ood detection approaches that either detect if specific situation and related input is ood or if the overall data distribution changes over given time period', 'uncertainty quantification methods for example on bayesian methods have been for ood detection but despite having mising potential they are at the moment not sufficient for ood detection especially for data where challenging ood samples can be encountered']"
