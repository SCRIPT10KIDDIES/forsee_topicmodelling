Topic,Count,Name,Representation,Representative_Docs
-1,33,-1_testing_digital_virtual_sovereignty,"['testing', 'digital', 'virtual', 'sovereignty', 'interoperability', 'development', 'standards', 'environments', 'deployment', 'trusted']","['for vehicles for example the development of standardized virtual testing environment may be required which in addition may lead to interoperability needs between the digital twins of the car and the environment model', 'these themes are fundamental considerations definitions and terminology defining the scope of the regulatory framework addressing the risks and values voluntary labelling of non ai systems role of digital sovereignty explainability ai testing safety and conformity assessment connecting with standardization shaping europe digital future european data strategy besides these recommendations the focus group is preparing european road map for ai standardization which is expected to be finalised in september', 'request european standardization organizations to come up with an overall standard for virtual testing facilities including standards for interoperability between digital twins and standardized virtual testing environment and standards for physical sensors actuators etc']"
0,31,0_white_machine_response_technologies,"['white', 'machine', 'response', 'technologies', 'data', 'terminology', 'ml', 'training', 'concepts', 'evolving']","['response to the ec white paper on ai version response to the ec white paper on ai executive summary this paper is the official response from on the ec white paper on ai', 'response to the ec white paper on ai version', 'response to the ec white paper on ai version']"
1,20,1_standardization_cenelec_cen_sovereignty,"['standardization', 'cenelec', 'cen', 'sovereignty', 'countries', 'toolkits', 'organizations', 'needs', 'standards', 'technologies']","['cen and cenelec would like to take this opportunity to comment on the white paper and on commission documents european strategy on data com and shaping europe digital future com which were released the same day', 'cen and cenelec are currently analysing whether relevant standards are already being produced at international level and if european standards covering specific european needs should also be produced', 'set standardization directions at the european commission level in order to address sovereignty properly and to lead in the adoption and standardization process of the future digital technologies']"
2,17,2_tc_cases_applications_cybersecurity,"['tc', 'cases', 'applications', 'cybersecurity', 'standards', 'toolkits', 'expert', 'governance', 'ethics', 'development']","['furthermore rooting good practice of ai use in eu research projects from the start of research programmes such as horizon europe will allow for those good practices to be promoted in every sector of the research programme health transport and any other leading to solid contribution to standards rooted in and use cases', 'besides sc also other iso and iec committees have ongoing standardization activities for artificial response to the ec white paper on ai version intelligence such as sc information security cybersecurity and privacy protection sc software and systems engineering iso tc safety of machinery iso tc road vehicles iso tc health informatics iec tc measurement control and automation and iec seg ethics in autonomous and artificial intelligence applications', 'actively use the csa coordination and support action type of funding available in the framework programme currently horizon soon horizon europe as well as ia innovation actions to ensure the dynamic development of standards for new ai core functionalities ai research or the use of proven ai in variety of systems ai engineering and sectorial use including in research aiming at an adequate standardization of ai in the eu while ensuring global standardization wherever possible for critical mass and scale']"
3,14,3_risks_outcomes_appointment_conflicts,"['risks', 'outcomes', 'appointment', 'conflicts', 'information', 'liability', 'requirements', 'privacy', 'records', 'medical']","['fund project call for recommendation and or technical solution that allows organizations to assess biased outcomes without increasing the organization access to personal data', 'even for applications that are not safety critical there are significant risks to society if ethical aspects of systems can not be validated for instance to detect biased outcomes based on personal data', 'risks of fundamental rights including personal data and privacy protection and and risks for safety and the effective functioning of the liability regime the related issues and types of legal requirements scoping the framework specifically on ai seems not appropriate']"
4,11,4_labelling_voluntary_standards_label,"['labelling', 'voluntary', 'standards', 'label', 'sources', 'trustworthy', 'fairness', 'ingredients', 'costs', 'suggestion']","['furthermore depending on the specific application various aspects safety fairness privacy security have different relevance which must be considered by such labelling scheme', 'to first promote the development and acceptance of these standards before introducing labelling scheme', 'voluntary labelling of non ai applications the suggestion of voluntary labelling regime sounds good in principle but meaningful labelling system will require careful thought as the absence of clear legal rules can create confusion if the labelling scheme is not trustworthy']"
5,11,5_values_rights_criteria_requirements,"['values', 'rights', 'criteria', 'requirements', 'discourse', 'safeguarding', 'prioritising', 'account', 'integrated', 'respect']","['provide specific requirements for values or rights so it can be integrated in the approach which takes proportionality into account', 'values or rights approach should therefore be an addition to the application approach', 'promote discourse on prioritising values and fundamental rights depending on circumstances and context and whether different values should be protected from risk in different ways']"
6,10,6_concepts_proper_spaces_expectations,"['concepts', 'proper', 'spaces', 'expectations', 'viewpoints', 'times', 'refers', 'ontology', 'broad', 'implementation']","['those three concepts look very similar and at least very complementary', 'both concepts look to go beyond pure data spaces', 'however such concepts need proper definition and ontology connection with other concepts for their proper acceptance and implementation']"
7,10,7_management_safety_standard_assessment,"['management', 'safety', 'standard', 'assessment', 'sectors', 'conformity', 'software', 'documentation', 'regulations', 'validation']","['along with the risk management for ai standard within iso future is there are other standardization bodies which are exploring how to address safety and conformity issues for ai applications', 'safety and conformity assessment safety and conformity assessment are an essential activity for ai applications risk management to ensure trustworthiness', 'standards setting requirements on such management structures including those on the management of risks and as part of risk management the impact assessment of ai the management of data related aspects such as quality statistical bias the documentation of testing and validation procedures and the establishment of structures for human oversight should be understood as measures to ensure and to document regulatory conformance on organizational level']"
8,9,8_sectors_risks_risk_significant,"['sectors', 'risks', 'risk', 'significant', 'evaluated', 'rare', 'compulsory', 'border', 'belts', 'decision']","['in second step applications in these sectors shall be evaluated concerning their risks', 'in first step sectors where significant risk can be expected shall be identified and listed in the regulatory framework as sectors', 'while in sectors more risks can be expected to occur this does not mean that significant risks will not also occur in sectors especially with the new scope of risks as defined by the white paper']"
9,8,9_standards_providing_safety_market,"['standards', 'providing', 'safety', 'market', 'malta', 'tape', 'efficient', 'facilitate', 'sustainability', 'policies']","['these standards which can be harmonised providing presumption of conformity with legal requirements make up around quarter of all european standards', 'by providing this support standardization makes it easier to sell products and services across europe and beyond therefore improving safety protecting consumers reducing red tape and fostering innovation', 'having one single standard created with the consensus of all interested parties and adopted across the european market instead of conflicting national standards helps significantly to ensure common levels of safety security and sustainability']"
10,8,10_regulatory_framework_scope_application,"['regulatory', 'framework', 'scope', 'application', 'trigger', 'scoped', 'identification', 'proposed', 'clause', 'organization']","['instead of scoping the regulatory framework on ai it should be scoped by the technology and application areas that fall under the framework', 'recommendations scope the regulatory framework around the relevant application behaviour and not around ai this includes the revision of', 'defining the scope of the regulatory framework the white paper states in clause key issue for the future specific regulatory framework on ai intelligence is to determine the scope of its application']"
11,8,11_services_verification_coverage_requirements,"['services', 'verification', 'coverage', 'requirements', 'properties', 'contractual', 'continual', 'revisions', 'notices', 'infrastructures']","['clear definition to which products and services the regulatory framework is relevant is indeed necessary in order to have legal certainty for all stakeholders', 'in systems the coverage of all relevant scenarios must be ensured by the sum of the defined rules and is equally important', 'but since internet based services will be frequently used in contexts as part of critical infrastructures and undergo frequent and dynamic changes updates and revisions therefore appropriate service management measures are needed to ensure that requirements such as the ones mentioned in section of the white paper are met on continual bases']"
12,8,12_explainability_transparency_technical_verifiability,"['explainability', 'transparency', 'technical', 'verifiability', 'needs', 'research', 'requirements', 'topics', 'developers', 'grounded']","['explainability the problem of explainability needs to be framed for different kinds of systems such as decision making or sensing systems', 'high level requirements for explainability need to be defined in international standards in concert with defining transparency and verifiability for ai applications and their relationship to explainability in various contexts and at various comprehension levels', 'develop metrics for explainability to tie in with high level conceptual requirements which can be developed into like workshop agreements or technical reports']"
